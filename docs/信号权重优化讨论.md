# 信号权重优化讨论

## 📋 问题背景

**日期**: 2025-11-11

**问题描述**: 
单个TOP100·6次信号就达到50%强度，权重过高。

**具体案例**:
- 东星医疗 (TOP100·6次) → 强度50%
- 单个信号占据了一半权重

---

## 🔍 问题分析

### 当前权重配置

```python
# 基础权重分配
HOT_LIST_WEIGHT = 0.25          # 🥇 T1: 热点榜 25%
RANK_JUMP_WEIGHT = 0.20         # 🥈 T2: 排名跳变 20%
VOLATILITY_SURGE_WEIGHT = 0.20  # 🥈 T2: 波动率上升 20%
STEADY_RISE_WEIGHT = 0.15       # 🥉 T3: 稳步上升 15%
PRICE_SURGE_WEIGHT = 0.10       # 🎖️ T4: 涨幅榜 10%
VOLUME_SURGE_WEIGHT = 0.10      # 🎖️ T4: 成交量榜 10%

# 热点榜档位倍数（当前）
TOP100:  2.0×  → 实际权重 0.5   (50%) ⚠️ 过高
TOP200:  1.5×  → 实际权重 0.375 (37.5%)
TOP400:  1.2×  → 实际权重 0.3   (30%)
TOP600:  1.0×  → 实际权重 0.25  (25%)
TOP800:  0.8×  → 实际权重 0.2   (20%)
TOP1000: 0.5×  → 实际权重 0.125 (12.5%)
TOP2000: 0.3×  → 实际权重 0.075 (7.5%)
TOP3000: 0.2×  → 实际权重 0.05  (5%)
```

### 核心问题

1. **单一信号权重过高**
   - TOP100信号 = 50%
   - 其他5个信号总和 = 75%
   - 比例失衡

2. **档位间隔不均匀**
   - TOP100→TOP200: 降12.5%
   - TOP200→TOP400: 降7.5%
   - TOP400→TOP600: 降5%
   - 衰减不符合规律

3. **缺乏统计学依据**
   - 倍数设置较随意
   - 未考虑排名分布特征

---

## 💡 优化方案对比

### 方案1：线性衰减（用户建议）✅

**档位倍数**:
```
TOP100:  1.3×  → 0.325 (32.5%)
TOP200:  1.2×  → 0.300 (30%)
TOP400:  1.1×  → 0.275 (27.5%)
TOP600:  1.0×  → 0.250 (25%)
TOP800:  0.9×  → 0.225 (22.5%)
TOP1000: 0.8×  → 0.200 (20%)
TOP2000: 0.7×  → 0.175 (17.5%)
TOP3000: 0.6×  → 0.150 (15%)
```

**配合次数加权**:
```
≥12次: ×1.2
≥10次: ×1.1
≥8次:  ×1.05
<8次:  ×1.0
```

**效果示例**:
```
TOP100·12次: 0.325 × 1.2 = 0.39  (39%) ← 最高
TOP100·6次:  0.325 × 1.0 = 0.325 (32.5%)
TOP1000·12次: 0.2 × 1.2 = 0.24  (24%)
TOP2000·10次: 0.175 × 1.1 = 0.19 (19%)
```

**优点**:
- ✅ 分数分布均匀
- ✅ 阶梯间隔固定（2.5%）
- ✅ 直观易懂
- ✅ 最高不超过40%

**缺点**:
- ⚠️ 线性衰减，不符合热点的自然分布
- ⚠️ 缺乏统计学理论支持

---

### 方案2：正态分布标准化 📊

**公式**:
```
score = μ + (rank_percentile - 0.5) × σ × base_weight

其中:
- μ = 1.0 (中心点)
- σ = 0.6 (标准差，控制分散度)
- rank_percentile = 1 - (rank / 3000)
- base_weight = 0.25
```

**效果示例**:
```
TOP100 (rank=50):  
  percentile = 0.983
  score = 1.0 + (0.983-0.5)×0.6 = 1.29
  final = 1.29 × 0.25 = 0.32 (32%)

TOP1000 (rank=500):
  percentile = 0.833
  score = 1.0 + (0.833-0.5)×0.6 = 1.20
  final = 1.20 × 0.25 = 0.30 (30%)

TOP2000 (rank=1500):
  percentile = 0.5
  score = 1.0 + 0×0.6 = 1.0
  final = 1.0 × 0.25 = 0.25 (25%)

TOP3000 (rank=2500):
  percentile = 0.167
  score = 1.0 + (0.167-0.5)×0.6 = 0.80
  final = 0.80 × 0.25 = 0.20 (20%)
```

**优点**:
- ✅ 符合统计学规律
- ✅ 分数分布平滑
- ✅ 可调整σ控制分散度
- ✅ 不会出现极端值

**缺点**:
- ⚠️ 实现复杂
- ⚠️ 不够直观

---

### 方案3：对数衰减 📉

**公式**:
```
score = base_weight × log(3001 - rank) / log(3000)
```

**效果示例**:
```
TOP100:   0.25 × 0.997 = 0.249 (24.9%)
TOP1000:  0.25 × 0.953 = 0.238 (23.8%)
TOP2000:  0.25 × 0.862 = 0.216 (21.6%)
TOP3000:  0.25 × 0.000 = 0.000 (0%)
```

**优点**:
- ✅ 平滑衰减
- ✅ 符合"头部效应"
- ✅ 自动处理边界

**缺点**:
- ⚠️ 区分度不够
- ⚠️ TOP100只有25%，偏低

---

### 方案4：幂律分布 ⚡

**公式**:
```
score = base_weight × (1 - (rank/3000)^α)
其中 α=0.3
```

**效果示例**:
```
TOP100:   0.25 × 0.68 = 0.17 (17%)
TOP1000:  0.25 × 0.28 = 0.07 (7%)
TOP2000:  0.25 × 0.10 = 0.025 (2.5%)
```

**优点**:
- ✅ 符合热点的幂律分布
- ✅ 头部权重高

**缺点**:
- ⚠️ 尾部衰减过快
- ⚠️ TOP100只有17%，偏低

---

## 🎯 推荐方案

**采用方案1（线性衰减）+ 次数加权**

### 理由

1. **直观可控**: 档位和倍数一目了然
2. **权重合理**: 最高39%，最低15%
3. **区分度好**: 每档相差2.5%，足够区分
4. **实现简单**: 无需复杂计算

### 实现细节

```python
# 档位倍数配置
rank_multipliers = {
    100: 1.3,
    200: 1.2,
    400: 1.1,
    600: 1.0,
    800: 0.9,
    1000: 0.8,
    2000: 0.7,
    3000: 0.6
}

# 次数加权
hit_count_multipliers = {
    12: 1.2,   # 持续热点
    10: 1.1,   # 稳定热点
    8: 1.05    # 一般热点
}

# 最终得分 = 基础权重 × 档位倍数 × 次数倍数
final_score = 0.25 × rank_mult × hit_mult
```

---

## 📊 对比表

| 方案 | TOP100·12次 | TOP100·6次 | TOP1000·12次 | TOP2000·10次 | 实现难度 |
|-----|------------|-----------|-------------|-------------|---------|
| 当前 | 60% | 50% | 15% | 9% | 简单 |
| 方案1 | 39% | 32.5% | 24% | 19% | 简单 ⭐ |
| 方案2 | 38.4% | 32% | 36% | 27.5% | 中等 |
| 方案3 | 29.9% | 24.9% | 28.6% | 23.8% | 中等 |
| 方案4 | 20.4% | 17% | 8.4% | 2.8% | 简单 |

---

## ✅ 实施记录

### 2025-11-11 修改完成

**实施方案**: 方案1（分层加权）

**修改内容**:
1. ✅ 删除配置版本检查机制（用户反馈容易出问题）
2. ✅ 应用分层加权倍数：
   ```python
   TOP100:  1.3×  # 32.5%
   TOP200:  1.2×  # 30%
   TOP400:  1.1×  # 27.5%
   TOP600:  1.0×  # 25%
   TOP800:  0.9×  # 22.5%
   TOP1000: 0.8×  # 20%
   TOP2000: 0.7×  # 17.5%
   TOP3000: 0.6×  # 15%
   ```
3. ✅ 次数加权保持：12次×1.2、10次×1.1、8次×1.05

**预期效果**:
- TOP100·12次：0.325 × 1.2 = **39%** (最高)
- TOP100·6次：0.325 × 1.0 = **32.5%** (合理)
- TOP1000·12次：0.2 × 1.2 = **24%**
- TOP2000·10次：0.175 × 1.1 = **19.25%**
- TOP3000·8次：0.15 × 1.05 = **15.75%**

**文件修改**:
- `backend/app/services/signal_calculator.py` - 第217-240行
- `frontend/src/contexts/SignalConfigContext.js` - 删除版本检查

---

## 📋 待办事项

- [x] 实现方案1的档位倍数
- [ ] 更新前端显示说明
- [ ] 添加单元测试
- [ ] 验证效果

---

**文档作者**: AI Assistant  
**创建日期**: 2025-11-11  
**最后更新**: 2025-11-11 13:35  
**状态**: 已实施
