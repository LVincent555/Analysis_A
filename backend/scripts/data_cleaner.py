"""
å­¤å„¿æ•°æ®æ¸…ç†å™¨
å¤„ç†warningçŠ¶æ€çš„æ•°æ®ï¼Œåˆ é™¤å¯¹åº”çš„æ•°æ®åº“è®°å½•
"""
import sys
import logging
from pathlib import Path
from typing import List, Optional
from import_state_manager import ImportStateManager
from app.database import SessionLocal
from app.db_models import DailyStockData, SectorDailyData
from sqlalchemy import func

logger = logging.getLogger(__name__)


class DataCleaner:
    """æ•°æ®æ¸…ç†å™¨"""
    
    def __init__(self, data_type='stock'):
        """
        Args:
            data_type: 'stock' æˆ– 'sector'
        """
        self.data_type = data_type
        state_file = (
            "data_import_state.json" if data_type == 'stock' 
            else "sector_import_state.json"
        )
        self.state_manager = ImportStateManager(state_file)
        self.model = DailyStockData if data_type == 'stock' else SectorDailyData
    
    def scan_warnings(self) -> dict:
        """æ‰«æè­¦å‘Š"""
        warnings = self.state_manager.get_warnings()
        
        if not warnings:
            logger.info(f"âœ… {self.data_type.upper()} æ•°æ®æ²¡æœ‰è­¦å‘Š")
            return {}
        
        logger.warning(
            f"âš ï¸  å‘ç° {len(warnings)} ä¸ªè­¦å‘ŠçŠ¶æ€çš„"
            f" {self.data_type.upper()} æ•°æ®ï¼š"
        )
        logger.warning("=" * 80)
        
        for date_str, import_info in sorted(warnings.items()):
            self._print_warning_detail(date_str, import_info)
        
        logger.warning("=" * 80)
        return warnings
    
    def clean_warnings(
        self, 
        dry_run=False, 
        dates: Optional[List[str]] = None,
        force=False
    ) -> dict:
        """
        æ¸…ç†è­¦å‘Šæ•°æ®
        
        Args:
            dry_run: é¢„æ¼”æ¨¡å¼
            dates: æŒ‡å®šæ—¥æœŸåˆ—è¡¨
            force: å¼ºåˆ¶æ¸…ç†æŒ‡å®šæ—¥æœŸï¼ˆå¿½ç•¥çŠ¶æ€ï¼‰
        """
        if force and dates:
            # å¼ºåˆ¶æ¸…ç†æ¨¡å¼ï¼šç›´æ¥åˆ é™¤æŒ‡å®šæ—¥æœŸçš„æ•°æ®
            logger.warning("ğŸ”¥ å¼ºåˆ¶æ¸…ç†æ¨¡å¼ï¼šå¿½ç•¥çŠ¶æ€ï¼Œç›´æ¥åˆ é™¤æŒ‡å®šæ—¥æœŸ")
            return self._force_clean_dates(dates, dry_run)
        
        warnings = self.state_manager.get_warnings()
        
        if not warnings:
            logger.info(f"âœ… {self.data_type.upper()} æ•°æ®æ²¡æœ‰è­¦å‘Š")
            return {'success': 0, 'failed': 0}
        
        # è¿‡æ»¤æ—¥æœŸ
        if dates:
            warnings = {d: w for d, w in warnings.items() if d in dates}
            if not warnings:
                logger.warning("âš ï¸  æŒ‡å®šçš„æ—¥æœŸæ²¡æœ‰è­¦å‘ŠçŠ¶æ€")
                return {'success': 0, 'failed': 0}
        
        mode = "[é¢„æ¼”æ¨¡å¼]" if dry_run else "[æ‰§è¡Œæ¨¡å¼]"
        logger.info(f"\n{mode} å¤„ç† {len(warnings)} ä¸ªè­¦å‘Š...")
        logger.info("=" * 80)
        
        success_count = 0
        failed_count = 0
        
        for date_str, import_info in sorted(warnings.items()):
            if self._clean_single_date(date_str, import_info, dry_run):
                success_count += 1
            else:
                failed_count += 1
        
        logger.info("\n" + "=" * 80)
        logger.info(f"âœ… æ¸…ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
        
        if dry_run:
            logger.info("\nğŸ’¡ è¿™æ˜¯é¢„æ¼”æ¨¡å¼ï¼Œæ²¡æœ‰çœŸæ­£åˆ é™¤æ•°æ®")
            logger.info("   è¿è¡Œ 'python update_daily_data.py clean' æ‰§è¡ŒçœŸå®åˆ é™¤")
        
        return {'success': success_count, 'failed': failed_count}
    
    def _clean_single_date(
        self, 
        date_str: str, 
        import_info: dict, 
        dry_run: bool
    ) -> bool:
        """æ¸…ç†å•ä¸ªæ—¥æœŸçš„æ•°æ®"""
        warning_info = import_info.get('warning_info', {}) or {}
        warning_type = warning_info.get('warning_type', 'unknown')
        
        logger.info(f"\nğŸ“… å¤„ç†æ—¥æœŸ: {date_str}")
        logger.info(f"   é—®é¢˜ç±»å‹: {warning_type}")
        logger.info(f"   æ–‡ä»¶: {import_info.get('filename')}")
        
        # åˆ é™¤æ•°æ®åº“æ•°æ®
        db_session = SessionLocal()
        try:
            count = db_session.query(func.count(self.model.id)).filter(
                func.to_char(self.model.date, 'YYYYMMDD') == date_str
            ).scalar()
            
            if count == 0:
                logger.info("  æ•°æ®åº“ä¸­æ²¡æœ‰æ•°æ®")
                return True
            
            if dry_run:
                logger.info(f"  [é¢„æ¼”] å°†åˆ é™¤ {count} æ¡è®°å½•")
                return True
            
            # çœŸå®åˆ é™¤ï¼ˆç¡¬åˆ é™¤ï¼‰
            logger.warning(f"  ğŸ—‘ï¸  åˆ é™¤ {count} æ¡è®°å½•...")
            deleted = db_session.query(self.model).filter(
                func.to_char(self.model.date, 'YYYYMMDD') == date_str
            ).delete(synchronize_session=False)
            
            db_session.commit()
            logger.info(f"  âœ… å·²åˆ é™¤ {deleted} æ¡è®°å½•")
            
            # æ›´æ–°çŠ¶æ€
            self.state_manager.mark_deleted(
                date_str,
                delete_reason=f"orphan_cleanup_{warning_type}",
                deleted_by="clean_script"
            )
            
            return True
            
        except Exception as e:
            db_session.rollback()
            logger.error(f"  âŒ åˆ é™¤å¤±è´¥: {str(e)}")
            return False
        finally:
            db_session.close()
    
    def _force_clean_dates(self, dates: List[str], dry_run: bool) -> dict:
        """
        å¼ºåˆ¶æ¸…ç†æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼ˆå¿½ç•¥çŠ¶æ€ï¼‰
        ç”¨äºå¤„ç† rolled_back ç­‰ç‰¹æ®Šæƒ…å†µ
        """
        mode = "[é¢„æ¼”æ¨¡å¼]" if dry_run else "[æ‰§è¡Œæ¨¡å¼]"
        logger.warning(f"\n{mode} å¼ºåˆ¶æ¸…ç† {len(dates)} ä¸ªæ—¥æœŸ...")
        logger.warning("=" * 80)
        
        success_count = 0
        failed_count = 0
        
        for date_str in dates:
            # è·å–å¯¼å…¥ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            import_info = self.state_manager.state["imports"].get(date_str, {
                "filename": f"{date_str}_*.xlsx",
                "status": "unknown"
            })
            
            if self._clean_single_date(date_str, import_info, dry_run):
                success_count += 1
            else:
                failed_count += 1
        
        logger.warning("\n" + "=" * 80)
        logger.warning(f"âœ… å¼ºåˆ¶æ¸…ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
        
        if dry_run:
            logger.info("\nğŸ’¡ è¿™æ˜¯é¢„æ¼”æ¨¡å¼ï¼Œæ²¡æœ‰çœŸæ­£åˆ é™¤æ•°æ®")
            logger.info("   è¿è¡Œ 'python update_daily_data.py clean --force --dates YYYYMMDD' æ‰§è¡ŒçœŸå®åˆ é™¤")
        
        return {'success': success_count, 'failed': failed_count}
    
    def _print_warning_detail(self, date_str: str, import_info: dict):
        """æ‰“å°è­¦å‘Šè¯¦æƒ…"""
        warning_info = import_info.get('warning_info', {}) or {}
        warning_type = warning_info.get('warning_type', 'unknown')
        detected_at = warning_info.get('detected_at', 'unknown')
        status = import_info.get('status', 'unknown')
        
        logger.warning(f"\nğŸ“… æ—¥æœŸ: {date_str}")
        logger.warning(f"   æ–‡ä»¶: {import_info.get('filename', 'N/A')}")
        logger.warning(f"   çŠ¶æ€: {status}")
        logger.warning(f"   é—®é¢˜: {warning_type}")
        logger.warning(f"   æ£€æµ‹æ—¶é—´: {detected_at}")
        logger.warning(f"   å¯¼å…¥è®°å½•æ•°: {import_info.get('imported_count', 0)}")
        
        if warning_type == 'file_missing':
            logger.warning("âš ï¸  Excelæ–‡ä»¶å·²ç¼ºå¤±ï¼Œæ•°æ®åº“ä¸­ä»æœ‰æ•°æ®")
        elif warning_type == 'file_changed':
            logger.warning("âš ï¸  Excelæ–‡ä»¶å·²å˜æ›´ï¼Œä¸å¯¼å…¥æ—¶ä¸ä¸€è‡´")
            logger.warning(f"   åŸå§‹Hash: {warning_info.get('original_hash', 'N/A')[:16]}...")
            current_hash = warning_info.get('current_hash')
            if current_hash:
                logger.warning(f"   å½“å‰Hash: {current_hash[:16]}...")
        elif warning_type == 'rollback_residue':
            logger.warning("âš ï¸  å¯¼å…¥å¤±è´¥å·²å›æ»šï¼Œä½†å¯èƒ½æœ‰æ•°æ®åº“æ®‹ç•™")
            rollback_reason = import_info.get('rollback_reason', '')
            if rollback_reason:
                # åªæ˜¾ç¤ºç¬¬ä¸€è¡Œé”™è¯¯ä¿¡æ¯
                first_line = rollback_reason.split('\n')[0]
                logger.warning(f"   å›æ»šåŸå› : {first_line}")


def main():
    """ç‹¬ç«‹è¿è¡Œ"""
    import argparse
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # æ·»åŠ è·¯å¾„
    sys.path.insert(0, str(Path(__file__).parent))
    
    parser = argparse.ArgumentParser(description='å­¤å„¿æ•°æ®æ¸…ç†å·¥å…·')
    parser.add_argument('--scan', action='store_true', help='æ‰«æè­¦å‘Š')
    parser.add_argument('--clean', action='store_true', help='æ¸…ç†è­¦å‘Šæ•°æ®')
    parser.add_argument('--dry-run', action='store_true', help='é¢„æ¼”æ¨¡å¼')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶æ¸…ç†ï¼ˆå¿½ç•¥çŠ¶æ€ï¼Œéœ€é…åˆ --dates ä½¿ç”¨ï¼‰')
    parser.add_argument(
        '--type', 
        choices=['stock', 'sector', 'all'], 
        default='all',
        help='æ•°æ®ç±»å‹'
    )
    parser.add_argument('--dates', type=str, help='æŒ‡å®šæ—¥æœŸï¼ˆé€—å·åˆ†éš”ï¼Œå¦‚: 20251111 æˆ– 20251111,20251112ï¼‰')
    
    args = parser.parse_args()
    
    # è§£ææ—¥æœŸ
    dates = None
    if args.dates:
        dates = [d.strip() for d in args.dates.split(',')]
    
    # æ‰«ææ¨¡å¼
    if args.scan:
        if args.type in ['stock', 'all']:
            logger.info("ğŸ“Š æ‰«æè‚¡ç¥¨æ•°æ®...")
            cleaner = DataCleaner('stock')
            cleaner.scan_warnings()
        
        if args.type in ['sector', 'all']:
            logger.info("\nğŸ“Š æ‰«ææ¿å—æ•°æ®...")
            cleaner = DataCleaner('sector')
            cleaner.scan_warnings()
        
        return 0
    
    # æ¸…ç†æ¨¡å¼
    if args.clean or args.dry_run or args.force:
        # å¼ºåˆ¶æ¨¡å¼éœ€è¦æŒ‡å®šæ—¥æœŸ
        if args.force and not dates:
            logger.error("âŒ å¼ºåˆ¶æ¸…ç†æ¨¡å¼å¿…é¡»æŒ‡å®š --dates å‚æ•°")
            return 1
        
        if not args.dry_run:
            logger.warning("âš ï¸  è­¦å‘Šï¼šå³å°†åˆ é™¤æ•°æ®åº“æ•°æ®ï¼")
            if args.force:
                logger.warning("ğŸ”¥ å¼ºåˆ¶æ¨¡å¼ï¼šå°†å¿½ç•¥çŠ¶æ€ç›´æ¥åˆ é™¤æŒ‡å®šæ—¥æœŸçš„æ•°æ®")
            response = input("ç¡®è®¤åˆ é™¤æ•°æ®ï¼Ÿ(yes/no): ")
            if response.lower() not in ['yes', 'y']:
                logger.info("âŒ å·²å–æ¶ˆ")
                return 1
        
        if args.type in ['stock', 'all']:
            logger.info("ğŸ“Š æ¸…ç†è‚¡ç¥¨æ•°æ®...")
            cleaner = DataCleaner('stock')
            cleaner.clean_warnings(dry_run=args.dry_run, dates=dates, force=args.force)
        
        if args.type in ['sector', 'all']:
            logger.info("\nğŸ“Š æ¸…ç†æ¿å—æ•°æ®...")
            cleaner = DataCleaner('sector')
            cleaner.clean_warnings(dry_run=args.dry_run, dates=dates, force=args.force)
        
        return 0
    
    # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©
    parser.print_help()
    return 0


if __name__ == "__main__":
    sys.exit(main())
