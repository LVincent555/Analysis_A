"""
å¯¼å…¥çŠ¶æ€ç®¡ç†å™¨
ç»´æŠ¤æ•°æ®å¯¼å…¥çš„åŸå­æ€§ã€å¹‚ç­‰æ€§å’Œå›æ»šæœºåˆ¶
ä½¿ç”¨æœ¬åœ°JSONæ–‡ä»¶å­˜å‚¨å¯¼å…¥çŠ¶æ€ï¼Œæ— ä¾µå…¥æ€§è®¾è®¡
"""
import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional
import logging

logger = logging.getLogger(__name__)


class ImportStateManager:
    """å¯¼å…¥çŠ¶æ€ç®¡ç†å™¨"""
    
    def __init__(self, state_file: str = "data_import_state.json"):
        """
        åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨
        
        Args:
            state_file: çŠ¶æ€æ–‡ä»¶åï¼ˆå­˜å‚¨åœ¨dataç›®å½•ä¸‹ï¼‰
        """
        # çŠ¶æ€æ–‡ä»¶å­˜å‚¨åœ¨dataç›®å½•
        from app.config import DATA_DIR
        self.state_file = Path(DATA_DIR) / state_file
        self.state = self._load_state()
    
    def _load_state(self) -> Dict:
        """åŠ è½½çŠ¶æ€æ–‡ä»¶ï¼ˆå…¼å®¹è€ç‰ˆæœ¬ï¼‰"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
                
                # === å…¼å®¹æ€§å¤„ç† ===
                # ç¡®ä¿versionå­—æ®µå­˜åœ¨
                if "version" not in state:
                    state["version"] = "1.0"
                    logger.info("æ£€æµ‹åˆ°è€ç‰ˆæœ¬JSONï¼Œå·²è‡ªåŠ¨å‡çº§")
                
                # ä¸ºæ¯ä¸ªå¯¼å…¥è®°å½•æ·»åŠ é»˜è®¤å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                for date_str, import_info in state.get("imports", {}).items():
                    # warning_infoå­—æ®µ
                    if "warning_info" not in import_info:
                        import_info["warning_info"] = None
                    
                    # deletion_infoå­—æ®µ
                    if "deletion_info" not in import_info:
                        import_info["deletion_info"] = None
                    
                    # dedup_infoå­—æ®µ
                    if "dedup_info" not in import_info:
                        import_info["dedup_info"] = None
                    
                    # data_fixeså­—æ®µï¼ˆæ–°å¢ï¼‰
                    if "data_fixes" not in import_info:
                        import_info["data_fixes"] = {}
                
                # ç¡®ä¿fix_configå­˜åœ¨ï¼ˆå‘å‰å…¼å®¹ï¼‰
                if "fix_config" not in state:
                    state["fix_config"] = {
                        "turnover_rate_fix": {
                            "enabled": True,
                            "auto_fix": True,
                            "threshold": 0.01,
                            "multiplier": 10000
                        }
                    }
                
                return state
                
            except Exception as e:
                logger.warning(f"çŠ¶æ€æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œåˆ›å»ºæ–°æ–‡ä»¶: {str(e)}")
                return self._create_empty_state()
        else:
            return self._create_empty_state()
    
    def _create_empty_state(self) -> Dict:
        """åˆ›å»ºç©ºçŠ¶æ€"""
        return {
            "version": "1.1",  # å‡çº§ç‰ˆæœ¬å·ä»¥æ”¯æŒä¿®è¡¥åŠŸèƒ½
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "database": "unknown",
            "imports": {},
            "fix_config": {
                "turnover_rate_fix": {
                    "enabled": True,
                    "auto_fix": True,
                    "threshold": 0.01,
                    "multiplier": 10000
                }
            }
        }
    
    def _save_state(self):
        """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        try:
            self.state["last_updated"] = datetime.now().isoformat()
            with open(self.state_file, 'w', encoding='utf-8') as f:
                json.dump(self.state, f, ensure_ascii=False, indent=2)
            logger.debug(f"çŠ¶æ€æ–‡ä»¶å·²ä¿å­˜: {self.state_file}")
        except Exception as e:
            logger.error(f"çŠ¶æ€æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")
    
    def save(self):
        """ä¿å­˜çŠ¶æ€åˆ°æ–‡ä»¶ï¼ˆå…¬å¼€æ–¹æ³•ï¼‰"""
        self._save_state()
    
    def calculate_file_hash(self, file_path: Path) -> str:
        """
        è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œå€¼
        ç”¨äºæ£€æµ‹æ–‡ä»¶æ˜¯å¦å˜åŒ–
        """
        try:
            md5_hash = hashlib.md5()
            with open(file_path, 'rb') as f:
                # åˆ†å—è¯»å–ï¼Œé¿å…å¤§æ–‡ä»¶å†…å­˜é—®é¢˜
                for chunk in iter(lambda: f.read(4096), b""):
                    md5_hash.update(chunk)
            return md5_hash.hexdigest()
        except Exception as e:
            logger.warning(f"æ–‡ä»¶å“ˆå¸Œè®¡ç®—å¤±è´¥: {str(e)}")
            return ""
    
    def is_imported(self, date_str: str) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šæ—¥æœŸæ˜¯å¦å·²æˆåŠŸå¯¼å…¥
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼Œæ ¼å¼ï¼š'20251103'
        
        Returns:
            Trueè¡¨ç¤ºå·²æˆåŠŸå¯¼å…¥ï¼ŒFalseè¡¨ç¤ºæœªå¯¼å…¥æˆ–å¤±è´¥
        """
        if date_str not in self.state["imports"]:
            return False
        
        import_info = self.state["imports"][date_str]
        return import_info.get("status") == "success"
    
    def should_reimport(self, date_str: str, file_path: Path) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°å¯¼å…¥
        
        åœºæ™¯ï¼š
        1. ä»æœªå¯¼å…¥è¿‡ -> éœ€è¦å¯¼å…¥
        2. ä¸Šæ¬¡å¤±è´¥ -> éœ€è¦é‡æ–°å¯¼å…¥
        3. æ–‡ä»¶å·²å˜åŒ–ï¼ˆå“ˆå¸Œä¸åŒï¼‰-> éœ€è¦é‡æ–°å¯¼å…¥
        4. ä¸Šæ¬¡æˆåŠŸä¸”æ–‡ä»¶æœªå˜ -> ä¸éœ€è¦å¯¼å…¥
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            file_path: æ–‡ä»¶è·¯å¾„
        
        Returns:
            Trueè¡¨ç¤ºéœ€è¦å¯¼å…¥ï¼ŒFalseè¡¨ç¤ºè·³è¿‡
        """
        if date_str not in self.state["imports"]:
            return True  # ä»æœªå¯¼å…¥
        
        import_info = self.state["imports"][date_str]
        
        # ä¸Šæ¬¡å¤±è´¥ï¼Œéœ€è¦é‡æ–°å¯¼å…¥
        if import_info.get("status") != "success":
            return True
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å˜åŒ–
        current_hash = self.calculate_file_hash(file_path)
        if current_hash and current_hash != import_info.get("file_hash", ""):
            logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶å˜åŒ–: {file_path.name}ï¼Œå°†é‡æ–°å¯¼å…¥")
            return True
        
        return False  # å·²æˆåŠŸå¯¼å…¥ä¸”æ–‡ä»¶æœªå˜
    
    def start_import(self, date_str: str, filename: str, file_path: Path):
        """
        å¼€å§‹å¯¼å…¥ï¼Œè®°å½•åˆå§‹çŠ¶æ€
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            filename: æ–‡ä»¶å
            file_path: æ–‡ä»¶è·¯å¾„
        """
        file_hash = self.calculate_file_hash(file_path)
        
        self.state["imports"][date_str] = {
            "filename": filename,
            "status": "in_progress",
            "file_hash": file_hash,
            "start_time": datetime.now().isoformat(),
            "imported_count": 0,
            "skipped_count": 0,
            "attempt_count": self.state["imports"].get(date_str, {}).get("attempt_count", 0) + 1,
            "dedup_info": None,  # å»é‡ä¿¡æ¯
            "data_fixes": {}     # ä¿®è¡¥ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰
        }
        self._save_state()
        logger.info(f"å¼€å§‹å¯¼å…¥: {date_str} - {filename}")
    
    def record_dedup_info(self, date_str: str, dedup_stats: dict):
        """
        è®°å½•å»é‡ä¿¡æ¯
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            dedup_stats: å»é‡ç»Ÿè®¡ä¿¡æ¯
        """
        if date_str in self.state["imports"]:
            if dedup_stats.get('has_duplicates'):
                self.state["imports"][date_str]["dedup_info"] = {
                    "detected_duplicates": dedup_stats.get('duplicate_codes', []),
                    "removed_count": dedup_stats.get('removed_count', 0),
                    "removed_details": dedup_stats.get('removed_details', []),
                    "dedup_time": datetime.now().isoformat()
                }
                self._save_state()
                logger.info(f"ğŸ“ å·²è®°å½•å»é‡ä¿¡æ¯: {date_str}")
    
    def mark_success(
        self,
        date_str: str,
        imported_count: int,
        skipped_count: int = 0,
        duration_seconds: float = 0
    ):
        """
        æ ‡è®°å¯¼å…¥æˆåŠŸ
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            imported_count: å¯¼å…¥è®°å½•æ•°
            skipped_count: è·³è¿‡è®°å½•æ•°
            duration_seconds: è€—æ—¶ï¼ˆç§’ï¼‰
        """
        if date_str in self.state["imports"]:
            self.state["imports"][date_str].update({
                "status": "success",
                "imported_count": imported_count,
                "skipped_count": skipped_count,
                "end_time": datetime.now().isoformat(),
                "duration_seconds": round(duration_seconds, 2),
                "error": None  # æ¸…é™¤ä¹‹å‰çš„é”™è¯¯
            })
            self._save_state()
            logger.info(f"âœ… å¯¼å…¥æˆåŠŸ: {date_str}, å¯¼å…¥{imported_count}æ¡, è·³è¿‡{skipped_count}æ¡")
    
    def mark_failed(self, date_str: str, error: str, imported_count: int = 0):
        """
        æ ‡è®°å¯¼å…¥å¤±è´¥
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            error: é”™è¯¯ä¿¡æ¯
            imported_count: å·²å¯¼å…¥è®°å½•æ•°ï¼ˆå¤±è´¥å‰ï¼‰
        """
        if date_str in self.state["imports"]:
            self.state["imports"][date_str].update({
                "status": "failed",
                "error": error,
                "imported_count": imported_count,
                "end_time": datetime.now().isoformat()
            })
            self._save_state()
            logger.error(f"âŒ å¯¼å…¥å¤±è´¥: {date_str}, é”™è¯¯: {error}")
    
    def mark_rolled_back(self, date_str: str, reason: str):
        """
        æ ‡è®°å·²å›æ»š
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            reason: å›æ»šåŸå› 
        """
        if date_str in self.state["imports"]:
            self.state["imports"][date_str].update({
                "status": "rolled_back",
                "rollback_reason": reason,
                "rollback_time": datetime.now().isoformat()
            })
            self._save_state()
            logger.warning(f"ğŸ”„ å·²å›æ»š: {date_str}, åŸå› : {reason}")
    
    def get_import_info(self, date_str: str) -> Optional[Dict]:
        """è·å–å¯¼å…¥ä¿¡æ¯"""
        return self.state["imports"].get(date_str)
    
    def get_all_imports(self) -> Dict:
        """è·å–æ‰€æœ‰å¯¼å…¥è®°å½•"""
        return self.state["imports"]
    
    def get_statistics(self) -> Dict:
        """
        è·å–å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡å­—å…¸
        """
        imports = self.state["imports"]
        total = len(imports)
        success = sum(1 for i in imports.values() if i.get("status") == "success")
        failed = sum(1 for i in imports.values() if i.get("status") == "failed")
        in_progress = sum(1 for i in imports.values() if i.get("status") == "in_progress")
        
        total_records = sum(i.get("imported_count", 0) for i in imports.values() if i.get("status") == "success")
        
        return {
            "total_files": total,
            "success_count": success,
            "failed_count": failed,
            "in_progress_count": in_progress,
            "total_records_imported": total_records,
            "success_rate": f"{success/total*100:.1f}%" if total > 0 else "0%"
        }
    
    def print_summary(self):
        """æ‰“å°å¯¼å…¥æ‘˜è¦"""
        stats = self.get_statistics()
        print("\n" + "=" * 60)
        print("å¯¼å…¥çŠ¶æ€æ‘˜è¦")
        print("=" * 60)
        print(f"æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"æˆåŠŸ: {stats['success_count']}")
        print(f"å¤±è´¥: {stats['failed_count']}")
        print(f"è¿›è¡Œä¸­: {stats['in_progress_count']}")
        print(f"æ€»å¯¼å…¥è®°å½•: {stats['total_records_imported']}")
        print(f"æˆåŠŸç‡: {stats['success_rate']}")
        print("=" * 60)
    
    def mark_warning(self, date_str: str, warning_type: str, current_hash: Optional[str] = None):
        """
        æ ‡è®°ä¸ºè­¦å‘ŠçŠ¶æ€
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            warning_type: è­¦å‘Šç±»å‹ (file_missing/file_changed)
            current_hash: å½“å‰æ–‡ä»¶hashï¼ˆå¦‚æœæ–‡ä»¶è¿˜å­˜åœ¨ï¼‰
        """
        if date_str in self.state["imports"]:
            import_info = self.state["imports"][date_str]
            original_status = import_info.get("status")
            
            # åªæœ‰æˆåŠŸçŠ¶æ€æ‰èƒ½æ ‡è®°ä¸ºwarning
            if original_status == "success":
                import_info["status"] = "warning"
                import_info["warning_info"] = {
                    "detected_at": datetime.now().isoformat(),
                    "warning_type": warning_type,
                    "original_hash": import_info.get("file_hash"),
                    "current_hash": current_hash,
                    "suggest_action": "delete_db_data" if warning_type == "file_missing" else "reimport_or_delete"
                }
                self._save_state()
                logger.warning(f"âš ï¸  æ ‡è®°ä¸ºè­¦å‘Š: {date_str}, ç±»å‹: {warning_type}")
    
    def clear_warning(self, date_str: str):
        """æ¸…é™¤è­¦å‘ŠçŠ¶æ€ï¼ˆæ¢å¤ä¸ºsuccessï¼‰"""
        if date_str in self.state["imports"]:
            import_info = self.state["imports"][date_str]
            if import_info.get("status") == "warning":
                import_info["status"] = "success"
                import_info.pop("warning_info", None)
                self._save_state()
                logger.info(f"âœ… æ¸…é™¤è­¦å‘Š: {date_str}")
    
    def mark_deleted(self, date_str: str, delete_reason: str, deleted_by: str = "manual"):
        """
        æ ‡è®°ä¸ºå·²åˆ é™¤çŠ¶æ€
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²
            delete_reason: åˆ é™¤åŸå› 
            deleted_by: åˆ é™¤æ–¹å¼ (manual/clean_script/auto)
        """
        if date_str in self.state["imports"]:
            import_info = self.state["imports"][date_str]
            
            # è®°å½•åˆ é™¤ä¿¡æ¯
            import_info["status"] = "deleted"
            import_info["deletion_info"] = {
                "deleted_at": datetime.now().isoformat(),
                "deleted_by": deleted_by,
                "delete_reason": delete_reason,
                "original_imported_count": import_info.get("imported_count", 0),
                "original_status": import_info.get("status", "unknown")
            }
            
            # æ¸…é™¤è­¦å‘Šä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            import_info.pop("warning_info", None)
            
            self._save_state()
            logger.info(f"ğŸ—‘ï¸  æ ‡è®°ä¸ºå·²åˆ é™¤: {date_str}, åŸå› : {delete_reason}")
    
    def get_warnings(self) -> Dict:
        """
        è·å–æ‰€æœ‰è­¦å‘ŠçŠ¶æ€çš„è®°å½•
        
        Returns:
            è­¦å‘Šè®°å½•å­—å…¸ {date: import_info}
        """
        warnings = {}
        for date_str, import_info in self.state["imports"].items():
            if import_info.get("status") == "warning":
                warnings[date_str] = import_info
        return warnings
    
    def scan_file_changes(self, data_dir: Path, file_pattern: str = "*_data_sma_feature_color.xlsx") -> Dict:
        """
        æ‰«ææ–‡ä»¶å˜åŒ–ï¼Œæ ‡è®°ç¼ºå¤±æˆ–å˜æ›´çš„æ–‡ä»¶
        åŒæ—¶æ£€æµ‹ rolled_back çŠ¶æ€çš„æ®‹ç•™æ•°æ®
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼
        
        Returns:
            æ‰«æç»“æœç»Ÿè®¡
        """
        file_missing_count = 0
        file_changed_count = 0
        file_ok_count = 0
        rolled_back_count = 0
        
        for date_str, import_info in self.state["imports"].items():
            status = import_info.get("status")
            
            # æ£€æµ‹ rolled_back çŠ¶æ€ï¼ˆå¯èƒ½æœ‰æ•°æ®åº“æ®‹ç•™ï¼‰
            if status == "rolled_back":
                self.mark_warning(date_str, "rollback_residue", None)
                rolled_back_count += 1
                logger.warning(
                    f"âš ï¸  å›æ»šçŠ¶æ€: {import_info.get('filename')} "
                    f"ï¼ˆå¯èƒ½æœ‰æ•°æ®åº“æ®‹ç•™ï¼‰"
                )
                continue
            
            # åªæ£€æŸ¥æˆåŠŸå¯¼å…¥çš„è®°å½•
            if status != "success":
                continue
            
            filename = import_info.get("filename")
            if not filename:
                continue
            
            file_path = data_dir / filename
            original_hash = import_info.get("file_hash")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not file_path.exists():
                self.mark_warning(date_str, "file_missing", None)
                file_missing_count += 1
                logger.warning(f"âš ï¸  æ–‡ä»¶ç¼ºå¤±: {filename}")
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å˜åŒ–
            current_hash = self.calculate_file_hash(file_path)
            if current_hash and original_hash and current_hash != original_hash:
                self.mark_warning(date_str, "file_changed", current_hash)
                file_changed_count += 1
                logger.warning(f"âš ï¸  æ–‡ä»¶å·²å˜åŒ–: {filename}")
                continue
            
            file_ok_count += 1
        
        return {
            "file_missing": file_missing_count,
            "file_changed": file_changed_count,
            "file_ok": file_ok_count,
            "rolled_back": rolled_back_count,
            "total_checked": file_missing_count + file_changed_count + file_ok_count + rolled_back_count
        }
    
    def reset(self):
        """é‡ç½®æ‰€æœ‰çŠ¶æ€ï¼ˆæ…ç”¨ï¼‰"""
        self.state = self._create_empty_state()
        self._save_state()
        logger.warning("âš ï¸  çŠ¶æ€æ–‡ä»¶å·²é‡ç½®")


# å…¨å±€å•ä¾‹
_state_manager = None


def get_state_manager() -> ImportStateManager:
    """è·å–çŠ¶æ€ç®¡ç†å™¨å•ä¾‹"""
    global _state_manager
    if _state_manager is None:
        _state_manager = ImportStateManager()
    return _state_manager
