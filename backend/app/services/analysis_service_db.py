"""
çƒ­ç‚¹åˆ†ææœåŠ¡ - Numpyç¼“å­˜ç‰ˆ

v0.5.0: ä½¿ç”¨ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿ
"""
from typing import List, Dict, Optional
from datetime import datetime
from collections import Counter, defaultdict
import logging
import ast

from ..database import SessionLocal
from ..db_models import Stock, DailyStockData
from ..models.analysis import AnalysisResult
from ..models.stock import StockInfo
from ..utils.board_filter import should_filter_stock
from .numpy_cache_middleware import numpy_cache
from ..core.caching import cache  # v0.5.0: ç»Ÿä¸€ç¼“å­˜
from sqlalchemy import desc

logger = logging.getLogger(__name__)


class AnalysisServiceDB:
    """çƒ­ç‚¹åˆ†ææœåŠ¡ï¼ˆå†…å­˜ç¼“å­˜ç‰ˆï¼‰"""
    
    # v0.5.0: ç¼“å­˜TTLæ”¹ä¸º25å°æ—¶
    CACHE_TTL = 90000
    CACHE_PREFIX = 'analysis'
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        pass  # ä½¿ç”¨å…¨å±€ api_cache
    
    def get_db(self):
        """è·å–æ•°æ®åº“ä¼šè¯ï¼ˆä»…åœ¨å¿…è¦æ—¶ä½¿ç”¨ï¼‰"""
        return SessionLocal()
    
    def get_available_dates(self) -> List[str]:
        """è·å–å¯ç”¨æ—¥æœŸåˆ—è¡¨ï¼ˆä»Numpyç¼“å­˜ï¼‰"""
        return numpy_cache.get_available_dates()
    
    def analyze_period(
        self,
        period: int = 3,
        max_count: int = 100,
        board_type: str = 'main',
        target_date: Optional[str] = None
    ) -> AnalysisResult:
        """
        å‘¨æœŸçƒ­ç‚¹åˆ†æ
        
        é€»è¾‘ï¼š
        1. ç®€å•SQLï¼šè·å–æœ€è¿‘Nå¤©çš„æ‰€æœ‰æ•°æ®
        2. åç«¯è®¡ç®—ï¼šç»Ÿè®¡æ¯åªè‚¡ç¥¨å‡ºç°æ¬¡æ•°
        3. åç«¯è®¡ç®—ï¼šç­›é€‰å’Œæ’åº
        
        Args:
            period: åˆ†æå‘¨æœŸï¼ˆå¤©æ•°ï¼‰
            max_count: æœ€å¤§è¿”å›æ•°é‡
            board_type: æ¿å—ç±»å‹ ('all': å…¨éƒ¨, 'main': ä¸»æ¿, 'bjs': åŒ—äº¤æ‰€)
            target_date: æŒ‡å®šæ—¥æœŸ (YYYYMMDDæ ¼å¼)ï¼Œä¸ä¼ åˆ™ä½¿ç”¨æœ€æ–°æ—¥æœŸ
        
        Returns:
            åˆ†æç»“æœ
        """
        # v0.5.0: ä½¿ç”¨ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿ
        cache_key = f"analyze_{period}_{max_count}_{board_type}_{target_date}"
        cached = cache.get_api_cache("analysis", cache_key)
        if cached is not None:
            logger.info(f"âœ¨ ç¼“å­˜å‘½ä¸­: {cache_key}")
            return cached
        
        logger.info(f"ğŸ”„ è®¡ç®—çƒ­ç‚¹åˆ†æ: period={period}, max_count={max_count}, board_type={board_type}")
        
        # 1. ä»å†…å­˜è·å–æ—¥æœŸèŒƒå›´
        if target_date:
            target_date_obj = datetime.strptime(target_date, '%Y%m%d').date()
        else:
            target_date_obj = numpy_cache.get_latest_date()
        
        if not target_date_obj:
            return AnalysisResult(
                period=period,
                total_stocks=0,
                stocks=[],
                start_date="",
                end_date="",
                all_dates=[]
            )
        
        # è·å–æœ€è¿‘Nå¤©æ—¥æœŸ
        all_dates = numpy_cache.get_dates_range(period * 2)  # å¤šå–ä¸€äº›ä»¥é˜²ä¸å¤Ÿ
        target_dates = [d for d in all_dates if d <= target_date_obj][:period]
        
        if not target_dates:
            return AnalysisResult(
                period=period,
                total_stocks=0,
                stocks=[],
                start_date="",
                end_date="",
                all_dates=[]
            )
        
        date_strs = [d.strftime('%Y%m%d') for d in target_dates]
        latest_date = target_dates[0]  # æœ€æ–°æ—¥æœŸ
        
        # 2. ä»Numpyç¼“å­˜è·å–æœ€æ–°æ—¥æœŸçš„TOP Nè‚¡ç¥¨ï¼ˆé”šå®šï¼‰
        latest_top_stocks = numpy_cache.get_top_n_by_rank(latest_date, max_count)
        
        # è·å–é”šå®šè‚¡ç¥¨çš„ä»£ç åˆ—è¡¨ï¼ˆåº”ç”¨æ¿å—è¿‡æ»¤ï¼‰
        anchor_stocks = set()
        for stock_data in latest_top_stocks:
            if should_filter_stock(stock_data['stock_code'], board_type):
                continue
            anchor_stocks.add(stock_data['stock_code'])
        
        # 3. ä»å†…å­˜è·å–è¿™äº›é”šå®šè‚¡ç¥¨åœ¨æ‰€æœ‰æ—¥æœŸçš„æ•°æ®
        stock_appearances = defaultdict(lambda: {
            'code': '',
            'name': '',
            'industry': '',
            'dates': [],
            'date_rank_info': []
        })
        
        for target_date_item in target_dates:
            # è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰æ•°æ® (è¿”å›Dictåˆ—è¡¨)
            daily_stocks = numpy_cache.get_all_by_date(target_date_item)
            
            for stock_data in daily_stocks:
                code = stock_data['stock_code']
                rank = stock_data['rank'] if stock_data['rank'] is not None else 9999
                
                # åªå¤„ç†é”šå®šçš„è‚¡ç¥¨ï¼Œä¸”åœ¨TOPèŒƒå›´å†…
                if code not in anchor_stocks or rank > max_count:
                    continue
                
                # è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
                if not stock_appearances[code]['code']:
                    stock_info = numpy_cache.get_stock_info(code)
                    if stock_info:
                        # å¤„ç†è¡Œä¸šå­—æ®µ
                        industry = stock_info.industry
                        if isinstance(industry, list) and industry:
                            industry = industry[0]
                        elif isinstance(industry, str):
                            if industry.startswith('[') and industry.endswith(']'):
                                try:
                                    industry_list = ast.literal_eval(industry)
                                    industry = industry_list[0] if industry_list else 'æœªçŸ¥'
                                except:
                                    industry = industry.strip('[]').strip("'\"")
                            elif not industry:
                                industry = 'æœªçŸ¥'
                        else:
                            industry = 'æœªçŸ¥'
                        
                        stock_appearances[code]['code'] = code
                        stock_appearances[code]['name'] = stock_info.stock_name
                        stock_appearances[code]['industry'] = industry
                
                # è®°å½•å‡ºç°ä¿¡æ¯
                date_str = target_date_item.strftime('%Y%m%d')
                stock_appearances[code]['dates'].append(date_str)
                stock_appearances[code]['date_rank_info'].append({
                    'date': date_str,
                    'rank': rank,
                    'price_change': stock_data['price_change'],
                    'turnover_rate': stock_data['turnover_rate'],
                    'volatility': stock_data['volatility'],
                })
        
        # 4. æ„å»ºç»“æœåˆ—è¡¨
        stocks_list = []
        for stock_data in stock_appearances.values():
            appears_count = len(stock_data['dates'])
            
            # è¿‡æ»¤ï¼šåªä¿ç•™å‡ºç°æ¬¡æ•°>=2çš„è‚¡ç¥¨
            if appears_count < 2:
                continue
            
            # å¯¹date_rank_infoæŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
            sorted_date_rank_info = sorted(
                stock_data['date_rank_info'], 
                key=lambda x: x['date']
            )
            
            # æœ€æ–°æ’åï¼ˆæ’åºåçš„æœ€åä¸€æ¡è®°å½•ï¼‰
            latest_rank = sorted_date_rank_info[-1]['rank']
            
            stocks_list.append(StockInfo(
                code=stock_data['code'],
                name=stock_data['name'],
                industry=stock_data['industry'],
                rank=latest_rank,
                count=appears_count,
                date_rank_info=sorted_date_rank_info
            ))
        
        # æŒ‰å‡ºç°æ¬¡æ•°æ’åºï¼ˆä»å¤šåˆ°å°‘ï¼‰
        stocks_list.sort(key=lambda x: x.count, reverse=True)
        
        # 5. åç«¯è®¡ç®—ï¼šè¡Œä¸šç»Ÿè®¡
        industry_counter = Counter(s.industry for s in stocks_list)
        industry_stats = [
            {"industry": industry, "count": count}
            for industry, count in industry_counter.most_common(10)
        ]
            
        # 6. æ„å»ºç»“æœå¹¶ç¼“å­˜
        result = AnalysisResult(
            period=period,
            total_stocks=len(stocks_list),
            stocks=stocks_list,
            start_date=date_strs[0] if date_strs else "",
            end_date=date_strs[-1] if date_strs else "",
            all_dates=date_strs
        )
        
        # v0.5.0: ä½¿ç”¨ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿ
        cache.set_api_cache("analysis", cache_key, result, ttl=self.CACHE_TTL)
        logger.info(f"âœ… çƒ­ç‚¹åˆ†æå®Œæˆå¹¶ç¼“å­˜: {len(stocks_list)}åªè‚¡ç¥¨, key={cache_key}")
        
        return result


# å…¨å±€å®ä¾‹
analysis_service_db = AnalysisServiceDB()
