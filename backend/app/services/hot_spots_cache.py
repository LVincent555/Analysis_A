"""
çƒ­ç‚¹æ¦œæ’åç¼“å­˜ç®¡ç†å™¨
ç”¨äºç¼“å­˜14å¤©èšåˆçƒ­ç‚¹æ¦œæ•°æ®ï¼Œæä¾›å¿«é€Ÿæ’åæŸ¥è¯¢
"""
import time
import logging
from typing import Optional, List, Dict
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class HotSpotsCache:
    """çƒ­ç‚¹æ¦œæ’åç¼“å­˜
    
    ç¼“å­˜ç»“æ„ï¼š
    {
        "20251107": {
            "data": [...],           # å®Œæ•´æ¦œå•æ•°æ®ï¼ˆå‰ç«¯å±•ç¤ºç”¨ï¼‰
            "rank_map": {...},       # {è‚¡ç¥¨ä»£ç : æ’å} æ˜ å°„ï¼ˆä¿¡å·è®¡ç®—ç”¨ï¼‰
            "timestamp": 1699603200  # ç¼“å­˜æ—¶é—´æˆ³
        }
    }
    """
    
    _cache: Dict[str, Dict] = {}
    _ttl: int = 86400  # 24å°æ—¶è¿‡æœŸ
    _max_days: int = 30  # æœ€å¤šä¿ç•™30å¤©å†å²æ•°æ®
    
    @classmethod
    def get_rank(cls, stock_code: str, date: str) -> Optional[tuple]:
        """è·å–è‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸçš„çƒ­ç‚¹æ¦œæ’åå’Œå‡ºç°æ¬¡æ•°
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸ (YYYYMMDD)
            
        Returns:
            (rank, hit_count, tier_counts) å…ƒç»„ï¼Œå¦‚æœä¸åœ¨æ¦œå•ä¸­è¿”å›None
            ä¾‹å¦‚ï¼š(15, 12, {100: 10, 200: 12, ...}) è¡¨ç¤ºæ’åç¬¬15ï¼Œæ€»å…±å‡ºç°12æ¬¡ï¼Œå„æ¡£ä½ç»Ÿè®¡
        """
        # ç¡®ä¿æ•°æ®å·²åŠ è½½
        if date not in cls._cache or cls._is_expired(date):
            cls._load_date(date)
        
        # ä»rank_mapå¿«é€ŸæŸ¥è¯¢ï¼ˆO(1)ï¼‰
        rank_map = cls._cache.get(date, {}).get("rank_map", {})
        rank_info = rank_map.get(stock_code)
        
        if rank_info:
            return (rank_info["rank"], rank_info["hit_count"], rank_info["tier_counts"])
        
        return None
    
    @classmethod
    def get_full_data(cls, date: str) -> List[dict]:
        """è·å–æŒ‡å®šæ—¥æœŸçš„å®Œæ•´çƒ­ç‚¹æ¦œæ•°æ®
        
        Args:
            date: æ—¥æœŸ (YYYYMMDD)
            
        Returns:
            å®Œæ•´æ¦œå•åˆ—è¡¨ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºï¼‰
        """
        # ç¡®ä¿æ•°æ®å·²åŠ è½½
        if date not in cls._cache or cls._is_expired(date):
            cls._load_date(date)
        
        return cls._cache.get(date, {}).get("data", [])
    
    @classmethod
    def preload_recent_dates(cls, days: int = 3):
        """é¢„åŠ è½½æœ€è¿‘Nå¤©çš„æ•°æ®
        
        Args:
            days: é¢„åŠ è½½å¤©æ•°
        """
        try:
            from .numpy_cache_middleware import numpy_cache
            
            # ä»Numpyç¼“å­˜è·å–æœ€è¿‘Nå¤©æ—¥æœŸ
            recent_dates = numpy_cache.get_dates_range(days)
            
            if not recent_dates:
                logger.warning("æ— å¯ç”¨æ—¥æœŸï¼Œè·³è¿‡çƒ­ç‚¹æ¦œç¼“å­˜é¢„åŠ è½½")
                return
            
            logger.info(f"é¢„åŠ è½½æœ€è¿‘{days}å¤©çš„çƒ­ç‚¹æ¦œæ•°æ®: {[d.strftime('%Y%m%d') for d in recent_dates]}")
            
            for date_obj in recent_dates:
                date_str = date_obj.strftime('%Y%m%d')
                cls._load_date(date_str)
                
            logger.info("çƒ­ç‚¹æ¦œæ•°æ®é¢„åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.error(f"é¢„åŠ è½½çƒ­ç‚¹æ¦œæ•°æ®å¤±è´¥: {e}")
    
    @classmethod
    def _load_date(cls, date: str):
        """ä»memory_cacheåŠ è½½æŒ‡å®šæ—¥æœŸçš„çƒ­ç‚¹æ¦œæ•°æ®
        
        Args:
            date: æ—¥æœŸ (YYYYMMDD)
        """
        try:
            from .numpy_cache_middleware import numpy_cache
            from datetime import datetime
            from collections import defaultdict
            
            logger.info(f"åŠ è½½çƒ­ç‚¹æ¦œæ•°æ®: {date}")
            
            # å°†å­—ç¬¦ä¸²æ—¥æœŸè½¬ä¸ºdateå¯¹è±¡
            target_date_obj = datetime.strptime(date, '%Y%m%d').date()
            
            # è·å–æœ€è¿‘14å¤©çš„æ—¥æœŸ
            all_dates = numpy_cache.index_mgr.get_all_dates()
            target_dates = [d for d in all_dates if d <= target_date_obj][:14]
            
            if not target_dates:
                logger.warning(f"æ—¥æœŸ {date} æ— å¯ç”¨æ•°æ®")
                return
            
            # ç»Ÿè®¡æ¯åªè‚¡ç¥¨åœ¨14å¤©å†…çš„å‡ºç°æ¬¡æ•°å’Œå„æ¡£ä½æ¬¡æ•°
            stock_appearances = defaultdict(lambda: {
                'count': 0, 
                'dates': [], 
                'latest_rank': 9999,
                'tier_counts': {  # å„æ¡£ä½å‡ºç°æ¬¡æ•°
                    100: 0, 200: 0, 400: 0, 600: 0, 800: 0, 1000: 0, 2000: 0, 3000: 0
                }
            })
            
            # è°ƒè¯•ï¼šè®°å½•äº‘å—åŸæŠ•çš„ç»Ÿè®¡è¿‡ç¨‹
            debug_code = '600239'
            debug_info = []
            
            for idx, date_obj in enumerate(target_dates):
                # è·å–è¯¥æ—¥æœŸçš„TOP3000è‚¡ç¥¨ï¼ˆæ‰©å±•èŒƒå›´ï¼‰- è¿”å›Dictåˆ—è¡¨
                daily_stocks = numpy_cache.get_top_n_by_rank(date_obj, 3000)
                
                for stock_data in daily_stocks:
                    code = stock_data['stock_code']
                    rank = stock_data['rank'] if stock_data['rank'] is not None else 9999
                    
                    stock_appearances[code]['count'] += 1
                    stock_appearances[code]['dates'].append(date_obj)
                    
                    # ç»Ÿè®¡å„æ¡£ä½å‡ºç°æ¬¡æ•°
                    if rank <= 100:
                        stock_appearances[code]['tier_counts'][100] += 1
                    if rank <= 200:
                        stock_appearances[code]['tier_counts'][200] += 1
                    if rank <= 400:
                        stock_appearances[code]['tier_counts'][400] += 1
                    if rank <= 600:
                        stock_appearances[code]['tier_counts'][600] += 1
                    if rank <= 800:
                        stock_appearances[code]['tier_counts'][800] += 1
                    if rank <= 1000:
                        stock_appearances[code]['tier_counts'][1000] += 1
                    if rank <= 2000:
                        stock_appearances[code]['tier_counts'][2000] += 1
                    if rank <= 3000:
                        stock_appearances[code]['tier_counts'][3000] += 1
                    
                    # è°ƒè¯•ï¼šè®°å½•äº‘å—åŸæŠ•æ¯å¤©çš„æ’å
                    if code == debug_code:
                        debug_info.append(f"{date_obj.strftime('%Y-%m-%d')}: æ’å{rank}")
                    
                    # è®°å½•æœ€æ–°ä¸€å¤©çš„æ’åï¼ˆç¬¬ä¸€ä¸ªæ—¥æœŸæ˜¯æœ€æ–°çš„ï¼‰
                    if idx == 0:
                        stock_appearances[code]['latest_rank'] = rank
                    
                    # è®°å½•è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼ˆé¦–æ¬¡ï¼‰
                    if 'name' not in stock_appearances[code]:
                        stock_info = numpy_cache.get_stock_info(code)
                        if stock_info:
                            stock_appearances[code]['name'] = stock_info.stock_name
                            stock_appearances[code]['industry'] = stock_info.industry or 'æœªçŸ¥'
            
            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼ˆDEBUGçº§åˆ«ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°ï¼‰
            if debug_code in stock_appearances:
                logger.debug(f"ğŸ” [{debug_code}äº‘å—åŸæŠ•] 14å¤©ç»Ÿè®¡è¯¦æƒ…:")
                for info in debug_info:
                    logger.debug(f"   {info}")
                tier_info = stock_appearances[debug_code]['tier_counts']
                logger.debug(f"   ğŸ“Š æ¡£ä½ç»Ÿè®¡: TOP100={tier_info[100]}æ¬¡, TOP200={tier_info[200]}æ¬¡, TOP400={tier_info[400]}æ¬¡, TOP600={tier_info[600]}æ¬¡")
                logger.debug(f"   ğŸ“Š æ¡£ä½ç»Ÿè®¡: TOP800={tier_info[800]}æ¬¡, TOP1000={tier_info[1000]}æ¬¡, TOP2000={tier_info[2000]}æ¬¡, TOP3000={tier_info[3000]}æ¬¡")
                logger.debug(f"   âœ… æ€»è®¡: {stock_appearances[debug_code]['count']}æ¬¡, æœ€æ–°æ’å: {stock_appearances[debug_code]['latest_rank']}")
            
            # æŒ‰æœ€æ–°æ’åæ’åºï¼ˆä¸æœ€æ–°çƒ­ç‚¹å¯¹é½ï¼‰ï¼Œè€Œä¸æ˜¯æŒ‰å‡ºç°æ¬¡æ•°
            sorted_stocks = sorted(
                stock_appearances.items(),
                key=lambda x: x[1]['latest_rank']  # æ”¹ä¸ºæŒ‰æœ€æ–°æ’åæ’åº
            )[:3000]  # æ‰©å±•åˆ°å‰3000å
            
            # æ„å»ºå®Œæ•´æ¦œå•æ•°æ®ï¼ˆä½¿ç”¨æœ€æ–°æ’åï¼Œä¸é‡æ–°ç¼–å·ï¼‰
            stocks = []
            for code, info in sorted_stocks:
                stock_data = {
                    'code': code,
                    'name': info['name'],
                    'industry': info['industry'],
                    'rank': info['latest_rank'],  # ä½¿ç”¨æœ€æ–°æ’å
                    'hit_count': info['count'],
                    'tier_counts': info['tier_counts']  # ä¿å­˜å„æ¡£ä½ç»Ÿè®¡
                }
                stocks.append(stock_data)
            
            # æ„å»ºrank_mapï¼ˆå¿«é€ŸæŸ¥è¯¢ç”¨ï¼ŒåŒ…å«æ’åã€æ¬¡æ•°å’Œæ¡£ä½ç»Ÿè®¡ï¼‰
            rank_map = {
                stock['code']: {
                    "rank": stock["rank"],
                    "hit_count": stock["hit_count"],
                    "tier_counts": stock["tier_counts"]
                }
                for stock in stocks
            }
            
            # æ·»åŠ rank_labelåˆ°æ¯åªè‚¡ç¥¨
            for stock in stocks:
                rank = stock["rank"]
                hit_count = stock["hit_count"]
                tier_counts = stock["tier_counts"]
                stock["rank_label"] = cls._get_rank_label(rank, hit_count, tier_counts)
            
            # å­˜å…¥ç¼“å­˜
            cls._cache[date] = {
                "data": stocks,
                "rank_map": rank_map,
                "timestamp": time.time()
            }
            
            logger.info(f"çƒ­ç‚¹æ¦œæ•°æ®åŠ è½½å®Œæˆ: {date}, å…±{len(stocks)}åªè‚¡ç¥¨")
            
            # æ¸…ç†è¿‡æœŸç¼“å­˜
            cls._cleanup_old_cache()
            
        except Exception as e:
            logger.error(f"åŠ è½½çƒ­ç‚¹æ¦œæ•°æ®å¤±è´¥ {date}: {e}")
            # å­˜å…¥ç©ºæ•°æ®é¿å…é‡å¤åŠ è½½
            cls._cache[date] = {
                "data": [],
                "rank_map": {},
                "timestamp": time.time()
            }
    
    @classmethod
    def _is_expired(cls, date: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        
        Args:
            date: æ—¥æœŸ
            
        Returns:
            True if expired
        """
        if date not in cls._cache:
            return True
        
        timestamp = cls._cache[date].get("timestamp", 0)
        return (time.time() - timestamp) > cls._ttl
    
    @classmethod
    def _cleanup_old_cache(cls):
        """æ¸…ç†è¶…è¿‡max_daysçš„æ—§ç¼“å­˜"""
        if len(cls._cache) <= cls._max_days:
            return
        
        # æŒ‰æ—¥æœŸæ’åºï¼Œä¿ç•™æœ€æ–°çš„max_dayså¤©
        sorted_dates = sorted(cls._cache.keys(), reverse=True)
        dates_to_remove = sorted_dates[cls._max_days:]
        
        for date in dates_to_remove:
            del cls._cache[date]
            logger.debug(f"æ¸…ç†æ—§ç¼“å­˜: {date}")
    
    @classmethod
    def _get_rank_label(cls, rank: int, hit_count: int, tier_counts: dict) -> str:
        """æ ¹æ®æ’åå’Œå„æ¡£ä½å‡ºç°æ¬¡æ•°è¿”å›æ ‡ç­¾ï¼ˆä¸signal_calculatoré€»è¾‘ä¸€è‡´ï¼‰
        
        Args:
            rank: æ’åï¼ˆ1-3000ï¼‰
            hit_count: 14å¤©å†…æ€»å‡ºç°æ¬¡æ•°ï¼ˆ2-14ï¼‰
            tier_counts: å„æ¡£ä½å‡ºç°æ¬¡æ•°å­—å…¸ {100: x, 200: y, ...}
            
        Returns:
            TOP600Â·3æ¬¡ | TOP800Â·4æ¬¡ | ...
            
        é€»è¾‘ï¼š
        1. æ ¹æ®rankç¡®å®šåŸºç¡€æ¡£ä½
        2. å¦‚æœè¯¥æ¡£ä½å‡ºç°æ¬¡æ•°<2ï¼Œå‘ä¸ŠæŸ¥æ‰¾æ›´å¤§æ¡£ä½
        3. è¿”å›ç¬¬ä¸€ä¸ªæ»¡è¶³>=2æ¬¡çš„æ¡£ä½æ ‡ç­¾
        """
        # ç¡®å®šåŸºç¡€æ¡£ä½
        tiers = [100, 200, 400, 600, 800, 1000, 2000, 3000]
        current_tier = None
        for tier in tiers:
            if rank <= tier:
                current_tier = tier
                break
        
        if not current_tier:
            return ""
        
        # ä»å½“å‰æ¡£ä½å¼€å§‹ï¼Œæ‰¾ç¬¬ä¸€ä¸ªæ»¡è¶³>=2æ¬¡çš„æ¡£ä½
        available_tiers = [t for t in tiers if t >= current_tier]
        
        for tier in available_tiers:
            count = tier_counts.get(tier, 0)
            if count >= 2:
                return f"TOP{tier}Â·{count}æ¬¡"
        
        # å¦‚æœéƒ½ä¸æ»¡è¶³ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""
    
    @classmethod
    def clear_cache(cls):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼ˆæµ‹è¯•ç”¨ï¼‰"""
        cls._cache.clear()
        logger.info("çƒ­ç‚¹æ¦œç¼“å­˜å·²æ¸…ç©º")
    
    @classmethod
    def get_cache_stats(cls) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
        
        Returns:
            {
                "cached_dates": [...],
                "total_dates": int,
                "memory_usage_kb": float
            }
        """
        import sys
        
        memory_bytes = sys.getsizeof(cls._cache)
        for date, data in cls._cache.items():
            memory_bytes += sys.getsizeof(data)
            memory_bytes += sys.getsizeof(data.get("data", []))
            memory_bytes += sys.getsizeof(data.get("rank_map", {}))
        
        return {
            "cached_dates": sorted(cls._cache.keys(), reverse=True),
            "total_dates": len(cls._cache),
            "memory_usage_kb": round(memory_bytes / 1024, 2)
        }
