"""
APIå“åº”äºŒçº§ç¼“å­˜
Phase 6: åŸºäº DiskCache çš„è·¨è¿›ç¨‹å…±äº«ç¼“å­˜

ç‰¹æ€§:
- è·¨è¿›ç¨‹å…±äº«ï¼ˆå¤š Worker æ¨¡å¼ä¸‹å†…å­˜ä¸ç¿»å€ï¼‰
- è‡ªåŠ¨è¿‡æœŸ (TTL)
- LRU æ·˜æ±°ç­–ç•¥
- é˜²ç¼“å­˜å‡»ç©¿ï¼ˆå•ä¸€åˆ›å»ºè€…æ¨¡å¼ï¼‰
"""

import os
import logging
import hashlib
import json
from typing import Any, Callable, Optional
from functools import wraps
from datetime import datetime

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥ diskcache
try:
    from diskcache import Cache, FanoutCache
    DISKCACHE_AVAILABLE = True
except ImportError:
    DISKCACHE_AVAILABLE = False
    logger.warning("âš ï¸ diskcache æœªå®‰è£…ï¼ŒAPIç¼“å­˜å°†ä½¿ç”¨å†…å­˜æ¨¡å¼")


class APICache:
    """
    APIå“åº”ç¼“å­˜
    
    æ”¯æŒä¸¤ç§æ¨¡å¼:
    - disk: ä½¿ç”¨ DiskCacheï¼ˆè·¨è¿›ç¨‹å…±äº«ï¼‰
    - memory: ä½¿ç”¨å†…å­˜å­—å…¸ï¼ˆå•è¿›ç¨‹ï¼Œå›é€€æ¨¡å¼ï¼‰
    """
    
    # é»˜è®¤ç¼“å­˜ç›®å½•
    DEFAULT_CACHE_DIR = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
        'data', 'cache'
    )
    
    # é»˜è®¤é…ç½®
    DEFAULT_SIZE_LIMIT = 500 * 1024 * 1024  # 500MB
    DEFAULT_TTL = 3600  # 1å°æ—¶
    
    def __init__(
        self,
        cache_dir: str = None,
        size_limit: int = None,
        default_ttl: int = None,
        mode: str = 'auto'
    ):
        """
        åˆå§‹åŒ–ç¼“å­˜
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•
            size_limit: ç¼“å­˜å¤§å°é™åˆ¶ï¼ˆå­—èŠ‚ï¼‰
            default_ttl: é»˜è®¤è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
            mode: 'auto'(è‡ªåŠ¨), 'disk', 'memory'
        """
        self.cache_dir = cache_dir or self.DEFAULT_CACHE_DIR
        self.size_limit = size_limit or self.DEFAULT_SIZE_LIMIT
        self.default_ttl = default_ttl or self.DEFAULT_TTL
        
        # ç»Ÿè®¡
        self._hits = 0
        self._misses = 0
        
        # æ ¹æ®æ¨¡å¼åˆå§‹åŒ–
        if mode == 'auto':
            mode = 'disk' if DISKCACHE_AVAILABLE else 'memory'
        
        self._mode = mode
        
        if mode == 'disk':
            self._init_disk_cache()
        else:
            self._init_memory_cache()
        
        logger.info(f"ğŸ“¦ APIç¼“å­˜åˆå§‹åŒ–: mode={mode}, dir={self.cache_dir}, limit={self.size_limit // 1024 // 1024}MB")
    
    def _init_disk_cache(self):
        """åˆå§‹åŒ–ç£ç›˜ç¼“å­˜"""
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # ä½¿ç”¨ FanoutCache æé«˜å¹¶å‘æ€§èƒ½
        self._cache = FanoutCache(
            self.cache_dir,
            shards=4,  # 4ä¸ªåˆ†ç‰‡
            size_limit=self.size_limit,
            eviction_policy='least-recently-used',
            statistics=True,  # å¯ç”¨ç»Ÿè®¡
        )
        logger.info(f"âœ… DiskCache åˆå§‹åŒ–æˆåŠŸ: {self.cache_dir}")
    
    def _init_memory_cache(self):
        """åˆå§‹åŒ–å†…å­˜ç¼“å­˜ï¼ˆå›é€€æ¨¡å¼ï¼‰"""
        from collections import OrderedDict
        import time
        
        class MemoryCache:
            """ç®€æ˜“å†…å­˜ç¼“å­˜"""
            def __init__(self, maxsize=1000):
                self._cache = OrderedDict()
                self._expire = {}
                self._maxsize = maxsize
            
            def get(self, key, default=None):
                if key in self._cache:
                    if self._expire.get(key, float('inf')) > time.time():
                        self._cache.move_to_end(key)
                        return self._cache[key]
                    else:
                        del self._cache[key]
                        del self._expire[key]
                return default
            
            def set(self, key, value, expire=None):
                # LRU æ·˜æ±°
                while len(self._cache) >= self._maxsize:
                    self._cache.popitem(last=False)
                
                self._cache[key] = value
                if expire:
                    self._expire[key] = time.time() + expire
            
            def delete(self, key):
                self._cache.pop(key, None)
                self._expire.pop(key, None)
            
            def clear(self):
                self._cache.clear()
                self._expire.clear()
            
            def __len__(self):
                return len(self._cache)
            
            def close(self):
                pass
        
        self._cache = MemoryCache()
        logger.info("âš ï¸ ä½¿ç”¨å†…å­˜ç¼“å­˜æ¨¡å¼ï¼ˆéè·¨è¿›ç¨‹å…±äº«ï¼‰")
    
    def _make_key(self, prefix: str, **kwargs) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        # æ’åºç¡®ä¿ç›¸åŒå‚æ•°ç”Ÿæˆç›¸åŒé”®
        sorted_params = sorted(kwargs.items())
        params_str = json.dumps(sorted_params, ensure_ascii=False, default=str)
        
        # ä½¿ç”¨ MD5 å“ˆå¸Œç”ŸæˆçŸ­é”®
        hash_str = hashlib.md5(params_str.encode()).hexdigest()[:12]
        
        return f"{prefix}:{hash_str}"
    
    def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        value = self._cache.get(key)
        if value is not None:
            self._hits += 1
            logger.debug(f"ğŸ¯ äºŒçº§ç¼“å­˜å‘½ä¸­: {key}")
            return value
        self._misses += 1
        logger.debug(f"âŒ äºŒçº§ç¼“å­˜æœªå‘½ä¸­: {key}")
        return None
    
    def set(self, key: str, value: Any, ttl: int = None):
        """è®¾ç½®ç¼“å­˜"""
        ttl = ttl or self.default_ttl
        self._cache.set(key, value, expire=ttl)
        logger.debug(f"ğŸ’¾ äºŒçº§ç¼“å­˜å†™å…¥: {key}, TTL={ttl}s")
    
    def get_or_create(
        self,
        key: str,
        creator_func: Callable,
        ttl: int = None
    ) -> Any:
        """
        è·å–ç¼“å­˜ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
        
        Args:
            key: ç¼“å­˜é”®
            creator_func: åˆ›å»ºå‡½æ•°ï¼ˆæ— å‚æ•°ï¼‰
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            ç¼“å­˜å€¼æˆ–åˆ›å»ºçš„æ–°å€¼
        """
        # å…ˆå°è¯•è·å–
        value = self.get(key)
        if value is not None:
            return value
        
        # ä¸å­˜åœ¨ï¼Œåˆ›å»º
        value = creator_func()
        self.set(key, value, ttl)
        
        return value
    
    def invalidate(self, pattern: str = None):
        """
        å¤±æ•ˆç¼“å­˜
        
        Args:
            pattern: é”®å‰ç¼€æ¨¡å¼ï¼ŒNone è¡¨ç¤ºæ¸…ç©ºå…¨éƒ¨
        """
        if pattern is None:
            self._cache.clear()
            logger.info("ğŸ—‘ï¸ æ¸…ç©ºå…¨éƒ¨APIç¼“å­˜")
        else:
            # DiskCache ä¸æ”¯æŒæ¨¡å¼åˆ é™¤ï¼Œéœ€è¦éå†
            if self._mode == 'disk':
                keys_to_delete = [k for k in self._cache if k.startswith(pattern)]
                for key in keys_to_delete:
                    self._cache.delete(key)
                logger.info(f"ğŸ—‘ï¸ æ¸…é™¤ {len(keys_to_delete)} ä¸ªåŒ¹é… '{pattern}' çš„ç¼“å­˜")
            else:
                # å†…å­˜æ¨¡å¼ä¸æ”¯æŒéå†ï¼Œç›´æ¥æ¸…ç©º
                self._cache.clear()
    
    def delete(self, key: str):
        """åˆ é™¤å•ä¸ªç¼“å­˜"""
        self._cache.delete(key)
    
    def stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total = self._hits + self._misses
        hit_rate = (self._hits / total * 100) if total > 0 else 0
        
        stats = {
            'mode': self._mode,
            'hits': self._hits,
            'misses': self._misses,
            'total_requests': total,
            'hit_rate': f"{hit_rate:.1f}%",
            'cache_dir': self.cache_dir if self._mode == 'disk' else None,
        }
        
        # DiskCache é¢å¤–ç»Ÿè®¡
        if self._mode == 'disk' and hasattr(self._cache, 'volume'):
            try:
                stats['size_mb'] = self._cache.volume() / 1024 / 1024
                stats['count'] = len(self._cache)
            except:
                pass
        
        return stats
    
    def close(self):
        """å…³é—­ç¼“å­˜"""
        if hasattr(self._cache, 'close'):
            self._cache.close()


def cached(prefix: str, ttl: int = 3600):
    """
    ç¼“å­˜è£…é¥°å™¨
    
    ç”¨æ³•:
    @cached('analysis', ttl=300)
    def get_analysis(period: int, top_n: int):
        ...
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = api_cache._make_key(prefix, args=args, **kwargs)
            
            # å°è¯•è·å–ç¼“å­˜
            result = api_cache.get(cache_key)
            if result is not None:
                logger.debug(f"âœ“ ç¼“å­˜å‘½ä¸­: {prefix}")
                return result
            
            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)
            
            # ç¼“å­˜ç»“æœ
            api_cache.set(cache_key, result, ttl)
            logger.debug(f"âœ“ ç¼“å­˜å†™å…¥: {prefix}")
            
            return result
        
        return wrapper
    return decorator


# å…¨å±€å•ä¾‹
api_cache = APICache()
