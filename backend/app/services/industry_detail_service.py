"""
æ¿å—æˆåˆ†è‚¡è¯¦ç»†åˆ†ææœåŠ¡
æä¾›æ¿å—æˆåˆ†è‚¡æŸ¥è¯¢ã€ä¿¡å·è®¡ç®—ã€è¶‹åŠ¿åˆ†æç­‰åŠŸèƒ½
"""
import logging
from typing import List, Optional, Dict
from datetime import date, datetime
from collections import defaultdict

from ..models.industry_detail import (
    StockSignalInfo, IndustryStocksResponse, IndustryDetailResponse,
    IndustryTrendResponse, IndustryCompareResponse
)
from ..utils.ttl_cache import TTLCache
from .memory_cache import memory_cache
from .signal_calculator import SignalCalculator, SignalThresholds

logger = logging.getLogger(__name__)


class IndustryDetailService:
    """æ¿å—æˆåˆ†è‚¡è¯¦ç»†åˆ†ææœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜"""
        self.cache = TTLCache(default_ttl_seconds=1800)  # 30åˆ†é’Ÿç¼“å­˜
    
    def get_industry_stocks(
        self,
        industry_name: str,
        target_date: Optional[str] = None,
        sort_mode: str = "rank",
        calculate_signals: bool = True,
        signal_thresholds: Optional[SignalThresholds] = None
    ) -> Optional[IndustryStocksResponse]:
        """
        è·å–æ¿å—æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆå®Œæ•´ç‰ˆï¼ŒPhase 2ï¼‰
        
        Args:
            industry_name: æ¿å—åç§°ï¼ˆå¦‚ï¼šé£Ÿå“ã€å»ºæï¼‰
            target_date: ç›®æ ‡æ—¥æœŸ YYYYMMDDï¼Œé»˜è®¤æœ€æ–°æ—¥æœŸ
            sort_mode: æ’åºæ¨¡å¼ rank|score|price_change|volume|signal
            calculate_signals: æ˜¯å¦è®¡ç®—ä¿¡å·ï¼ˆPhase 2åŠŸèƒ½ï¼‰
            signal_thresholds: ä¿¡å·é˜ˆå€¼é…ç½®ï¼ŒNoneä½¿ç”¨é»˜è®¤å€¼
        
        Returns:
            æ¿å—æˆåˆ†è‚¡åˆ—è¡¨å“åº”
        """
        # ç¼“å­˜keyï¼ˆåŒ…å«ä¿¡å·è®¡ç®—æ ‡å¿—å’Œé˜ˆå€¼é…ç½®ï¼‰
        # å¦‚æœå¼€å¯ä¿¡å·è®¡ç®—ï¼Œç¼“å­˜keyéœ€è¦åŒ…å«é˜ˆå€¼é…ç½®ï¼Œå¦åˆ™ä¿®æ”¹é…ç½®åä»è¿”å›æ—§ç»“æœ
        if calculate_signals and signal_thresholds:
            logger.info(f"ğŸ“Š ä¿¡å·é…ç½®: mode={signal_thresholds.hot_list_mode}, version={signal_thresholds.hot_list_version}")
            threshold_hash = (
                f"{signal_thresholds.hot_list_mode}_"
                f"{signal_thresholds.hot_list_version}_"
                f"{signal_thresholds.hot_list_top}_"
                f"{signal_thresholds.rank_jump_min}_"
                f"{signal_thresholds.steady_rise_days_min}_"
                f"{signal_thresholds.price_surge_min}_"
                f"{signal_thresholds.volume_surge_min}_"
                f"{signal_thresholds.volatility_surge_min}"
            )
            cache_key = f"industry_stocks_{industry_name}_{target_date}_{sort_mode}_{calculate_signals}_{threshold_hash}"
        else:
            cache_key = f"industry_stocks_{industry_name}_{target_date}_{sort_mode}_{calculate_signals}"
        
        if cache_key in self.cache:
            logger.info(f"âœ¨ ç¼“å­˜å‘½ä¸­: {cache_key}")
            return self.cache[cache_key]
        
        logger.info(f"ğŸ”„ æŸ¥è¯¢æ¿å—æˆåˆ†è‚¡: {industry_name}, æ—¥æœŸ: {target_date}, æ’åº: {sort_mode}")
        
        # 1. ç¡®å®šæŸ¥è¯¢æ—¥æœŸ
        if target_date:
            query_date = datetime.strptime(target_date, '%Y%m%d').date()
        else:
            query_date = memory_cache.get_latest_date()
        
        if not query_date:
            logger.warning("æ— å¯ç”¨æ—¥æœŸ")
            return None
        
        # 2. ä»å†…å­˜ç¼“å­˜è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰æ•°æ®
        all_stocks = memory_cache.get_daily_data_by_date(query_date)
        if not all_stocks:
            logger.warning(f"æ—¥æœŸ {query_date} æ— æ•°æ®")
            return None
        
        # 3. ç­›é€‰è¯¥æ¿å—çš„è‚¡ç¥¨
        industry_stocks = []
        for stock_data in all_stocks:
            stock_info = memory_cache.get_stock_info(stock_data.stock_code)
            if stock_info and stock_info.industry:
                # å¤„ç†è¡Œä¸šå­—æ®µï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨æ ¼å¼ï¼‰
                industry = stock_info.industry
                if isinstance(industry, list) and industry:
                    industry = industry[0]
                elif isinstance(industry, str) and industry:
                    if industry.startswith('['):
                        try:
                            import ast
                            industry_list = ast.literal_eval(industry)
                            industry = industry_list[0] if industry_list else None
                        except:
                            industry = industry.strip('[]').strip("'\"")
                
                # åŒ¹é…è¡Œä¸šåç§°
                if industry == industry_name:
                    industry_stocks.append((stock_info, stock_data))
        
        if not industry_stocks:
            logger.warning(f"æ¿å— {industry_name} æ— æˆåˆ†è‚¡")
            return None
        
        logger.info(f"  æ‰¾åˆ° {len(industry_stocks)} åªæˆåˆ†è‚¡")
        
        # 4. åˆå§‹åŒ–ä¿¡å·è®¡ç®—å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        signal_calculator = None
        if calculate_signals:
            signal_calculator = SignalCalculator(signal_thresholds)
            logger.info(f"  è®¡ç®—ä¿¡å·ä¸­...")
        
        # 5. æ„å»ºå“åº”æ•°æ®ï¼ˆå®Œæ•´ç‰ˆï¼ŒåŒ…å«ä¿¡å·ï¼‰
        stocks_list = []
        for stock_info, stock_data in industry_stocks:
            # åŸºç¡€æ•°æ®
            stock_signal = StockSignalInfo(
                stock_code=stock_info.stock_code,
                stock_name=stock_info.stock_name,
                rank=stock_data.rank,
                total_score=float(stock_data.total_score) if stock_data.total_score else 0.0,
                price_change=float(stock_data.price_change) if stock_data.price_change else None,
                turnover_rate_percent=float(stock_data.turnover_rate_percent) if stock_data.turnover_rate_percent else None,
                volume_days=float(stock_data.volume_days) if stock_data.volume_days else None,
                market_cap_billions=float(stock_data.market_cap_billions) if stock_data.market_cap_billions else None,
            )
            
            # è®¡ç®—ä¿¡å·ï¼ˆPhase 2ï¼‰
            if signal_calculator:
                signal_data = signal_calculator.calculate_signals(
                    stock_code=stock_info.stock_code,
                    current_date=query_date,
                    current_data=stock_data,
                    history_days=7,
                    simplify_hot_labels=True  # ğŸ”¥ è¡Œä¸šæ¿å—ï¼šç®€åŒ–çƒ­ç‚¹æ ‡ç­¾ï¼Œé¿å…ä¿¡å·æ±¡æŸ“
                )
                # å¡«å……ä¿¡å·æ•°æ®
                stock_signal.signals = signal_data['signals']
                stock_signal.signal_count = signal_data['signal_count']
                stock_signal.signal_strength = signal_data['signal_strength']
                stock_signal.in_hot_list = signal_data['in_hot_list']
                stock_signal.in_rank_jump = signal_data['in_rank_jump']
                stock_signal.rank_improvement = signal_data['rank_improvement']
                stock_signal.in_steady_rise = signal_data['in_steady_rise']
                stock_signal.rise_days = signal_data['rise_days']
                stock_signal.in_price_surge = signal_data['in_price_surge']
                stock_signal.in_volume_surge = signal_data['in_volume_surge']
                stock_signal.signal_history = signal_data['signal_history']
            
            stocks_list.append(stock_signal)
        
        # 5. æ’åº
        stocks_list = self._sort_stocks(stocks_list, sort_mode, signal_thresholds)
        
        # 6. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        statistics = self._calculate_statistics(stocks_list, query_date)
        
        # 7. æ„å»ºå“åº”
        response = IndustryStocksResponse(
            industry=industry_name,
            date=query_date.strftime('%Y%m%d'),
            stock_count=len(stocks_list),
            stocks=stocks_list,
            statistics=statistics
        )
        
        # 8. ç¼“å­˜ç»“æœ
        self.cache[cache_key] = response
        logger.info(f"âœ… æ¿å—æˆåˆ†è‚¡æŸ¥è¯¢å®Œæˆ: {industry_name}, {len(stocks_list)}åª")
        
        return response
    
    def _sort_stocks(self, stocks: List[StockSignalInfo], sort_mode: str, signal_thresholds: Optional[SignalThresholds] = None) -> List[StockSignalInfo]:
        """
        æ’åºè‚¡ç¥¨åˆ—è¡¨
        
        Args:
            stocks: è‚¡ç¥¨åˆ—è¡¨
            sort_mode: æ’åºæ¨¡å¼
            signal_thresholds: ä¿¡å·é˜ˆå€¼é…ç½®ï¼ˆç”¨äºåˆ¤æ–­ç‰ˆæœ¬ï¼‰
            
        Returns:
            æ’åºåçš„è‚¡ç¥¨åˆ—è¡¨
        """
        if sort_mode == "rank":
            # æŒ‰å…¨å¸‚åœºæ’åå‡åºï¼ˆæ’åå°çš„åœ¨å‰ï¼‰
            return sorted(stocks, key=lambda x: x.rank)
        elif sort_mode == "score":
            # æŒ‰æ€»åˆ†é™åº
            return sorted(stocks, key=lambda x: x.total_score, reverse=True)
        elif sort_mode == "price_change":
            # æŒ‰æ¶¨è·Œå¹…é™åº
            return sorted(stocks, key=lambda x: x.price_change or -999, reverse=True)
        elif sort_mode == "volume":
            # æŒ‰æ¢æ‰‹ç‡é™åº
            return sorted(stocks, key=lambda x: x.turnover_rate_percent or -999, reverse=True)
        elif sort_mode == "signal":
            # Phase 2: æŒ‰ä¿¡å·æ’åºï¼Œæ ¹æ®ç‰ˆæœ¬å†³å®šä¼˜å…ˆçº§
            # v1åŸç‰ˆï¼šä¼˜å…ˆä¿¡å·æ•°é‡ï¼ˆå¤šä¿¡å·å…±æŒ¯ï¼‰
            # v2æ–°ç‰ˆï¼šä¼˜å…ˆä¿¡å·å¼ºåº¦ï¼ˆè´¨é‡ä¼˜å…ˆï¼‰
            version = signal_thresholds.hot_list_version if signal_thresholds else "v2"
            logger.info(f"ğŸ”„ æŒ‰ä¿¡å·æ’åºï¼Œversion={version}, ä¼˜å…ˆçº§={'æ•°é‡>å¼ºåº¦' if version=='v1' else 'å¼ºåº¦>æ•°é‡'}")
            if signal_thresholds and signal_thresholds.hot_list_version == "v1":
                # åŸç‰ˆï¼šæ•°é‡ > å¼ºåº¦ > æ’å
                return sorted(stocks, key=lambda x: (
                    -x.signal_count,     # ç¬¬1ä¼˜å…ˆçº§ï¼šä¿¡å·æ•°é‡
                    -x.signal_strength,  # ç¬¬2ä¼˜å…ˆçº§ï¼šä¿¡å·å¼ºåº¦
                    x.rank               # ç¬¬3ä¼˜å…ˆçº§ï¼šåŸå§‹æ’å
                ))
            else:
                # æ–°ç‰ˆï¼ˆé»˜è®¤ï¼‰ï¼šå¼ºåº¦ > æ•°é‡ > æ’å
                return sorted(stocks, key=lambda x: (
                    -x.signal_strength,  # ç¬¬1ä¼˜å…ˆçº§ï¼šä¿¡å·å¼ºåº¦ï¼ˆç™¾åˆ†æ¯”ï¼‰
                    -x.signal_count,     # ç¬¬2ä¼˜å…ˆçº§ï¼šä¿¡å·æ•°é‡
                    x.rank               # ç¬¬3ä¼˜å…ˆçº§ï¼šåŸå§‹æ’å
                ))
        elif sort_mode == "signal_count":
            # æŒ‰ä¿¡å·æ•°é‡æ’åºï¼ˆä¼˜å…ˆçº§ï¼šæ•°é‡ > å¼ºåº¦ > æ’åï¼‰
            return sorted(stocks, key=lambda x: (
                -x.signal_count,     # ç¬¬1ä¼˜å…ˆçº§ï¼šä¿¡å·æ•°é‡
                -x.signal_strength,  # ç¬¬2ä¼˜å…ˆçº§ï¼šä¿¡å·å¼ºåº¦
                x.rank               # ç¬¬3ä¼˜å…ˆçº§ï¼šåŸå§‹æ’å
            ))
        else:
            # é»˜è®¤æŒ‰æ’å
            return sorted(stocks, key=lambda x: x.rank)
    
    def _calculate_statistics(
        self,
        stocks: List[StockSignalInfo],
        query_date: date
    ) -> Dict:
        """
        è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            stocks: è‚¡ç¥¨åˆ—è¡¨
            query_date: æŸ¥è¯¢æ—¥æœŸ
        
        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        if not stocks:
            return {}
        
        # åŸºç¡€ç»Ÿè®¡
        total = len(stocks)
        ranks = [s.rank for s in stocks]
        avg_rank = sum(ranks) / total if total > 0 else 0
        
        # åˆ†å±‚ç»Ÿè®¡
        top_100 = sum(1 for s in stocks if s.rank <= 100)
        top_500 = sum(1 for s in stocks if s.rank <= 500)
        top_1000 = sum(1 for s in stocks if s.rank <= 1000)
        
        # æ¶¨è·Œå¹…ç»Ÿè®¡
        price_changes = [s.price_change for s in stocks if s.price_change is not None]
        avg_price_change = sum(price_changes) / len(price_changes) if price_changes else 0
        
        # ä¿¡å·ç»Ÿè®¡ï¼ˆPhase 2ï¼‰
        hot_list_count = sum(1 for s in stocks if s.in_hot_list)
        rank_jump_count = sum(1 for s in stocks if s.in_rank_jump)
        steady_rise_count = sum(1 for s in stocks if s.in_steady_rise)
        multi_signal_count = sum(1 for s in stocks if s.signal_count >= 2)
        
        # å¹³å‡ä¿¡å·å¼ºåº¦
        signal_strengths = [s.signal_strength for s in stocks]
        avg_signal_strength = sum(signal_strengths) / len(signal_strengths) if signal_strengths else 0.0
        
        statistics = {
            "avg_rank": round(avg_rank, 1),
            "top_100_count": top_100,
            "top_500_count": top_500,
            "top_1000_count": top_1000,
            "avg_price_change": round(avg_price_change, 2),
            "date": query_date.strftime('%Y%m%d'),
            # Phase 2 ä¿¡å·ç»Ÿè®¡
            "hot_list_count": hot_list_count,
            "rank_jump_count": rank_jump_count,
            "steady_rise_count": steady_rise_count,
            "multi_signal_count": multi_signal_count,
            "avg_signal_strength": round(avg_signal_strength, 3),
        }
        
        return statistics
    
    def get_industry_detail(
        self,
        industry_name: str,
        target_date: Optional[str] = None,
        k_value: float = 0.618
    ) -> Optional[IndustryDetailResponse]:
        """
        è·å–æ¿å—è¯¦ç»†åˆ†æï¼ˆåŒ…å«4ç»´æŒ‡æ ‡ B1/B2/C1/C2ï¼‰
        
        Args:
            industry_name: æ¿å—åç§°
            target_date: ç›®æ ‡æ—¥æœŸ YYYYMMDD
            k_value: Kå€¼ï¼ˆæƒé‡è¡°å‡å‚æ•°ï¼‰
        
        Returns:
            æ¿å—è¯¦ç»†åˆ†æå“åº”
        """
        # ç¼“å­˜key
        cache_key = f"industry_detail_{industry_name}_{target_date}_{k_value}"
        if cache_key in self.cache:
            logger.info(f"âœ¨ ç¼“å­˜å‘½ä¸­: {cache_key}")
            return self.cache[cache_key]
        
        logger.info(f"ğŸ”„ æŸ¥è¯¢æ¿å—è¯¦ç»†åˆ†æ: {industry_name}, K={k_value}")
        
        # 1. è·å–æˆåˆ†è‚¡æ•°æ®
        stocks_response = self.get_industry_stocks(
            industry_name=industry_name,
            target_date=target_date,
            sort_mode="rank",
            calculate_signals=True
        )
        
        if not stocks_response:
            return None
        
        # 2. è®¡ç®—4ç»´æŒ‡æ ‡ï¼ˆä½¿ç”¨Kå€¼åŠ æƒï¼‰
        b1, b2, c1, c2 = self._calculate_four_metrics(
            stocks_response.stocks, k_value
        )
        
        # 3. æ„å»ºå“åº”
        response = IndustryDetailResponse(
            industry=industry_name,
            date=stocks_response.date,
            stock_count=stocks_response.stock_count,
            B1=b1,
            B2=b2,
            C1=c1,
            C2=c2,
            avg_rank=stocks_response.statistics['avg_rank'],
            top_100_count=stocks_response.statistics['top_100_count'],
            top_500_count=stocks_response.statistics['top_500_count'],
            top_1000_count=stocks_response.statistics['top_1000_count'],
            hot_list_count=stocks_response.statistics['hot_list_count'],
            rank_jump_count=stocks_response.statistics['rank_jump_count'],
            steady_rise_count=stocks_response.statistics['steady_rise_count'],
            multi_signal_count=stocks_response.statistics['multi_signal_count'],
            avg_signal_strength=stocks_response.statistics['avg_signal_strength']
        )
        
        # 4. ç¼“å­˜ç»“æœ
        self.cache[cache_key] = response
        logger.info(f"âœ… æ¿å—è¯¦ç»†åˆ†æå®Œæˆ: {industry_name}")
        
        return response
    
    def _calculate_four_metrics(
        self,
        stocks: List[StockSignalInfo],
        k: float
    ) -> tuple:
        """
        è®¡ç®—4ç»´æŒ‡æ ‡ B1/B2/C1/C2
        
        Args:
            stocks: è‚¡ç¥¨åˆ—è¡¨ï¼ˆå·²æŒ‰æ’åæ’åºï¼‰
            k: Kå€¼å‚æ•°
        
        Returns:
            (B1, B2, C1, C2)
        """
        if not stocks:
            return 0.0, 0.0, 0.0, 0.0
        
        # æŒ‰æ’åæ’åº
        sorted_stocks = sorted(stocks, key=lambda x: x.rank)
        
        total_weight = 0.0
        weighted_score = 0.0
        weighted_price_change = 0.0
        weighted_volume = 0.0
        
        for i, stock in enumerate(sorted_stocks):
            # Kå€¼åŠ æƒï¼šw = k^i
            weight = k ** i
            total_weight += weight
            
            # B1: åŠ æƒæ€»åˆ†
            weighted_score += stock.total_score * weight
            
            # B2: åŠ æƒæ¶¨è·Œå¹…
            if stock.price_change is not None:
                weighted_price_change += stock.price_change * weight
            
            # C1/C2: åŠ æƒæˆäº¤é‡ç›¸å…³æŒ‡æ ‡
            if stock.turnover_rate_percent is not None:
                weighted_volume += stock.turnover_rate_percent * weight
        
        # å½’ä¸€åŒ–
        B1 = round(weighted_score / total_weight, 2) if total_weight > 0 else 0.0
        B2 = round(weighted_price_change / total_weight, 2) if total_weight > 0 else 0.0
        C1 = round(weighted_volume / total_weight, 2) if total_weight > 0 else 0.0
        
        # C2: ç®€åŒ–ç‰ˆï¼Œä½¿ç”¨volume_daysçš„åŠ æƒå¹³å‡
        weighted_volume_days = 0.0
        for i, stock in enumerate(sorted_stocks):
            weight = k ** i
            if stock.volume_days is not None:
                weighted_volume_days += stock.volume_days * weight
        C2 = round(weighted_volume_days / total_weight, 2) if total_weight > 0 else 0.0
        
        return B1, B2, C1, C2
    
    def get_industry_trend(
        self,
        industry_name: str,
        period: int = 7,
        k_value: float = 0.618
    ) -> Optional[IndustryTrendResponse]:
        """
        è·å–æ¿å—å†å²è¶‹åŠ¿
        
        Args:
            industry_name: æ¿å—åç§°
            period: è¿½è¸ªå¤©æ•°
            k_value: Kå€¼å‚æ•°
        
        Returns:
            æ¿å—å†å²è¶‹åŠ¿å“åº”
        """
        # ç¼“å­˜keyï¼ˆè¶‹åŠ¿æ•°æ®ç¼“å­˜æ—¶é—´æ›´é•¿ï¼š60åˆ†é’Ÿï¼‰
        cache_key = f"industry_trend_{industry_name}_{period}_{k_value}"
        cache = TTLCache(default_ttl_seconds=3600)  # 60åˆ†é’Ÿ
        if cache_key in cache:
            logger.info(f"âœ¨ ç¼“å­˜å‘½ä¸­: {cache_key}")
            return cache[cache_key]
        
        logger.info(f"ğŸ”„ æŸ¥è¯¢æ¿å—å†å²è¶‹åŠ¿: {industry_name}, {period}å¤©")
        
        # è·å–æœ€è¿‘Nå¤©çš„æ—¥æœŸ
        dates = memory_cache.get_dates_range(period)
        if not dates:
            return None
        
        dates = dates[:period]  # å–å‰Nå¤©
        
        # æ”¶é›†æ¯å¤©çš„æŒ‡æ ‡
        metrics_history = {
            'B1': [],
            'B2': [],
            'C1': [],
            'C2': [],
            'avg_rank': [],
            'top_100_count': [],
            'hot_list_count': [],
            'avg_signal_strength': []
        }
        date_strs = []
        
        for d in dates:
            date_str = d.strftime('%Y%m%d')
            
            # è·å–è¯¥æ—¥æœŸçš„æ¿å—è¯¦æƒ…
            detail = self.get_industry_detail(
                industry_name=industry_name,
                target_date=date_str,
                k_value=k_value
            )
            
            if detail:
                metrics_history['B1'].append(detail.B1)
                metrics_history['B2'].append(detail.B2)
                metrics_history['C1'].append(detail.C1)
                metrics_history['C2'].append(detail.C2)
                metrics_history['avg_rank'].append(detail.avg_rank)
                metrics_history['top_100_count'].append(detail.top_100_count)
                metrics_history['hot_list_count'].append(detail.hot_list_count)
                metrics_history['avg_signal_strength'].append(detail.avg_signal_strength)
                date_strs.append(date_str)
        
        if not date_strs:
            return None
        
        # æ„å»ºå“åº”
        response = IndustryTrendResponse(
            industry=industry_name,
            period=len(date_strs),
            dates=date_strs,
            metrics_history=metrics_history
        )
        
        cache[cache_key] = response
        logger.info(f"âœ… æ¿å—å†å²è¶‹åŠ¿å®Œæˆ: {industry_name}, {len(date_strs)}å¤©")
        
        return response
    
    def compare_industries(
        self,
        industry_names: List[str],
        target_date: Optional[str] = None,
        k_value: float = 0.618
    ) -> IndustryCompareResponse:
        """
        å¤šæ¿å—å¯¹æ¯”ï¼ˆ2-5ä¸ªï¼‰
        
        Args:
            industry_names: æ¿å—åç§°åˆ—è¡¨ï¼ˆ2-5ä¸ªï¼‰
            target_date: ç›®æ ‡æ—¥æœŸ YYYYMMDD
            k_value: Kå€¼å‚æ•°
        
        Returns:
            æ¿å—å¯¹æ¯”å“åº”
        """
        logger.info(f"ğŸ”„ å¯¹æ¯”æ¿å—: {industry_names}, K={k_value}")
        
        # ç¡®å®šæ—¥æœŸ
        if target_date:
            query_date = datetime.strptime(target_date, '%Y%m%d').date()
        else:
            query_date = memory_cache.get_latest_date()
        
        # è·å–æ¯ä¸ªæ¿å—çš„è¯¦ç»†æ•°æ®
        industries_detail = []
        for industry_name in industry_names:
            detail = self.get_industry_detail(
                industry_name=industry_name,
                target_date=query_date.strftime('%Y%m%d') if query_date else None,
                k_value=k_value
            )
            if detail:
                industries_detail.append(detail)
        
        # æ„å»ºå“åº”
        response = IndustryCompareResponse(
            date=query_date.strftime('%Y%m%d') if query_date else "",
            k_value=k_value,
            industries=industries_detail
        )
        
        logger.info(f"âœ… æ¿å—å¯¹æ¯”å®Œæˆ: {len(industries_detail)}ä¸ªæ¿å—")
        
        return response


# å…¨å±€å®ä¾‹
industry_detail_service = IndustryDetailService()
