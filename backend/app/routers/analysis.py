"""
åˆ†æç›¸å…³APIè·¯ç”±
"""
from fastapi import APIRouter, HTTPException
from ..services.analysis_service_db import analysis_service_db
from ..services.hot_spots_cache import HotSpotsCache
from ..services.numpy_cache_middleware import numpy_cache  # âœ… è¿ç§»åˆ°æ–°æ¶æ„
from ..models import AnalysisResult, AvailableDates

router = APIRouter(prefix="/api", tags=["analysis"])

# ä½¿ç”¨æ•°æ®åº“æœåŠ¡
analysis_service = analysis_service_db


@router.get("/dates", response_model=AvailableDates)
def get_available_dates():  # âœ… æ”¹ä¸ºåŒæ­¥ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
    """è·å–å¯ç”¨çš„æ—¥æœŸåˆ—è¡¨"""
    try:
        dates = analysis_service.get_available_dates()
        return AvailableDates(
            dates=dates,
            latest_date=dates[0] if dates else ""
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analyze/{period}", response_model=AnalysisResult)
def analyze_period(period: int, board_type: str = 'main', top_n: int = 100, date: str = None):  # âœ… åŒæ­¥
    """
    åˆ†ææŒ‡å®šå‘¨æœŸçš„è‚¡ç¥¨é‡å¤æƒ…å†µ
    
    Args:
        period: åˆ†æå‘¨æœŸï¼ˆå¤©æ•°ï¼‰
        board_type: æ¿å—ç±»å‹ ('all': å…¨éƒ¨, 'main': ä¸»æ¿, 'bjs': åŒ—äº¤æ‰€)
        top_n: æ¯å¤©åˆ†æå‰Nä¸ªè‚¡ç¥¨ï¼Œé»˜è®¤100ï¼Œå¯é€‰100/200/400/600/800/1000/2000/3000
        date: æŒ‡å®šæ—¥æœŸ (YYYYMMDDæ ¼å¼)ï¼Œä¸ä¼ åˆ™ä½¿ç”¨æœ€æ–°æ—¥æœŸ
    """
    try:
        import logging
        import sys
        logger = logging.getLogger(__name__)
        
        # è¯¦ç»†æ—¥å¿—ï¼šè®°å½•åŸå§‹å‚æ•°
        sys.stderr.write(f"\nğŸ” Routerå±‚æ”¶åˆ°å‚æ•°:\n")
        sys.stderr.write(f"   period={period} (type: {type(period).__name__})\n")
        sys.stderr.write(f"   top_n={top_n} (type: {type(top_n).__name__})\n")
        sys.stderr.write(f"   board_type={board_type} (type: {type(board_type).__name__})\n")
        sys.stderr.flush()
        
        # ç¡®ä¿top_næ˜¯æ•´æ•°ï¼ˆFastAPIåº”è¯¥å·²ç»è½¬æ¢äº†ï¼Œä½†ä»¥é˜²ä¸‡ä¸€ï¼‰
        top_n = int(top_n)
        
        # å‚æ•°éªŒè¯
        if top_n not in [100, 200, 400, 600, 800, 1000, 2000, 3000]:
            sys.stderr.write(f"âš ï¸  è­¦å‘Š: top_n={top_n} ä¸åœ¨å…è®¸èŒƒå›´å†…ï¼Œä½¿ç”¨é»˜è®¤å€¼100\n")
            sys.stderr.flush()
            top_n = 100  # é»˜è®¤å€¼
        
        logger.info(f"ğŸ¯ APIè°ƒç”¨å‚æ•°: period={period}, top_n={top_n}, board_type={board_type}, date={date}")
        
        return analysis_service.analyze_period(period, max_count=top_n, board_type=board_type, target_date=date)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/hot-spots/full")
def get_hot_spots_full(date: str = None):  # âœ… åŒæ­¥
    """
    è·å–å®Œæ•´çƒ­ç‚¹æ¦œæ•°æ®ï¼ˆå¸¦rank_labelï¼‰
    
    v0.5.0: ä½¿ç”¨ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿ
    
    è¿”å›14å¤©TOP1000çƒ­ç‚¹æ¦œï¼ŒåŒ…å«æ’åæ ‡ç­¾å’Œå‡ºç°æ¬¡æ•°
    ç”¨äºå‰ç«¯æœç´¢åŠŸèƒ½
    
    Args:
        date: æŒ‡å®šæ—¥æœŸ (YYYYMMDDæ ¼å¼)ï¼Œä¸ä¼ åˆ™ä½¿ç”¨æœ€æ–°æ—¥æœŸ
    
    Returns:
        {
            "date": "20251107",
            "total_count": 1000,
            "stocks": [...]
        }
    """
    try:
        import logging
        from ..core.caching import cache
        logger = logging.getLogger(__name__)
        
        # è·å–ç›®æ ‡æ—¥æœŸ
        if not date:
            from ..services.numpy_cache_middleware import numpy_cache
            latest_date_obj = numpy_cache.get_latest_date()
            if latest_date_obj:
                date = latest_date_obj.strftime('%Y%m%d')
            else:
                raise HTTPException(status_code=404, detail="æ— å¯ç”¨æ—¥æœŸ")
        
        # v0.5.0: ä¼˜å…ˆä»ç»Ÿä¸€ç¼“å­˜è¯»å–
        cache_key = f"hotspots_full_{date}"
        cached = cache.get_api_cache("hotspots", cache_key)
        if cached:
            logger.debug(f"âœ¨ çƒ­ç‚¹æ¦œç¼“å­˜å‘½ä¸­: {date}")
            return cached
        
        logger.info(f"è·å–çƒ­ç‚¹æ¦œå®Œæ•´æ•°æ®: date={date}")
        
        # ä» HotSpotsCache è·å–æ•°æ®
        stocks = HotSpotsCache.get_full_data(date)
        
        result = {
            "date": date,
            "total_count": len(stocks),
            "stocks": stocks
        }
        
        # å­˜å…¥ç»Ÿä¸€ç¼“å­˜ (TTL=25å°æ—¶)
        cache.set_api_cache("hotspots", cache_key, result, ttl=90000)
        
        return result
        
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"è·å–çƒ­ç‚¹æ¦œæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/market/volatility-summary")
def get_market_volatility_summary(days: int = 3):  # âœ… åŒæ­¥
    """
    è·å–å¸‚åœºæ³¢åŠ¨ç‡æ±‡æ€»æ•°æ®
    
    è¿”å›æœ€è¿‘Nå¤©çš„å…¨å¸‚åœºå¹³å‡æ³¢åŠ¨ç‡ï¼Œç”¨äºé¡¶æ å±•ç¤º
    
    Args:
        days: è¿”å›æœ€è¿‘Nå¤©çš„æ•°æ®ï¼Œé»˜è®¤3å¤©
    
    Returns:
        {
            "current": 2.35,
            "days": [
                {"date": "20251127", "avg_volatility": 2.35, "stock_count": 5000},
                {"date": "20251126", "avg_volatility": 2.42, "stock_count": 5000},
                {"date": "20251125", "avg_volatility": 2.18, "stock_count": 5000}
            ],
            "trend": "down",  // up/down/flat
            "stock_count": 5435
        }
    """
    try:
        result = numpy_cache.get_market_volatility_summary(days=days)
        
        if 'error' in result:
            raise HTTPException(status_code=500, detail=result['error'])
        
        return result
        
    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"è·å–å¸‚åœºæ³¢åŠ¨ç‡æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
