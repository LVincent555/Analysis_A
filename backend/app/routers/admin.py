"""
ç®¡ç†å‘˜è·¯ç”± - æ–‡ä»¶ä¸Šä¼ å’Œæ•°æ®å¯¼å…¥
ä»… admin è§’è‰²å¯è®¿é—®
"""
import os
import base64
import logging
from datetime import datetime
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException, status
from pydantic import BaseModel

from ..auth.dependencies import get_current_user
from ..db_models import User

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/admin", tags=["admin"])

# æ•°æ®ç›®å½•ï¼ˆä½¿ç”¨ config ä¸­çš„ç»Ÿä¸€é…ç½®ï¼‰
from ..config import DATA_DIR

# å¯¼å…¥çŠ¶æ€å­˜å‚¨ï¼ˆç®€å•çš„å†…å­˜å­˜å‚¨ï¼Œé‡å¯åæ¸…ç©ºï¼‰
import_status = {
    "is_importing": False,
    "current_file": None,
    "progress": 0,
    "last_import": None,
    "last_result": None,
    "history": [],
    "logs": []  # å®æ—¶æ—¥å¿—
}

# æœ€å¤§æ—¥å¿—æ¡æ•°
MAX_LOGS = 100

def add_log(message: str, level: str = "info"):
    """æ·»åŠ æ—¥å¿—åˆ°çŠ¶æ€"""
    from datetime import datetime
    log_entry = {
        "time": datetime.now().strftime("%H:%M:%S"),
        "level": level,
        "message": message
    }
    import_status["logs"].append(log_entry)
    # ä¿æŒæ—¥å¿—æ•°é‡é™åˆ¶
    if len(import_status["logs"]) > MAX_LOGS:
        import_status["logs"] = import_status["logs"][-MAX_LOGS:]
    # åŒæ—¶è¾“å‡ºåˆ°æœåŠ¡å™¨æ—¥å¿—
    if level == "error":
        logger.error(message)
    else:
        logger.info(message)


def require_admin(current_user: User = Depends(get_current_user)) -> User:
    """è¦æ±‚ç®¡ç†å‘˜æƒé™"""
    if current_user.role != "admin":
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="éœ€è¦ç®¡ç†å‘˜æƒé™"
        )
    return current_user


class FileUploadRequest(BaseModel):
    """æ–‡ä»¶ä¸Šä¼ è¯·æ±‚"""
    filename: str  # æ–‡ä»¶å
    content: str   # Base64 ç¼–ç çš„æ–‡ä»¶å†…å®¹
    

class ImportRequest(BaseModel):
    """å¯¼å…¥è¯·æ±‚"""
    date: Optional[str] = None  # å¯é€‰çš„æ—¥æœŸå‚æ•° YYYYMMDD


class UploadResponse(BaseModel):
    """ä¸Šä¼ å“åº”"""
    success: bool
    message: str
    filepath: Optional[str] = None


@router.post("/upload", response_model=UploadResponse)
async def upload_file(
    file_data: FileUploadRequest,
    current_user: User = Depends(require_admin)
):
    """
    ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨ data ç›®å½•
    æ–‡ä»¶å†…å®¹éœ€è¦ Base64 ç¼–ç 
    """
    try:
        # éªŒè¯æ–‡ä»¶å
        filename = file_data.filename
        if not filename:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
        
        # åªå…è®¸ xlsx å’Œ xls æ–‡ä»¶
        if not filename.lower().endswith(('.xlsx', '.xls')):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒ Excel æ–‡ä»¶ (.xlsx, .xls)")
        
        # è§£ç  Base64 å†…å®¹
        try:
            file_content = base64.b64decode(file_data.content)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Base64 è§£ç å¤±è´¥: {str(e)}")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ 10MBï¼‰
        if len(file_content) > 10 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡ 10MB")
        
        # ç¡®ä¿ data ç›®å½•å­˜åœ¨
        os.makedirs(DATA_DIR, exist_ok=True)
        
        # ä¿å­˜æ–‡ä»¶
        filepath = os.path.join(DATA_DIR, filename)
        with open(filepath, 'wb') as f:
            f.write(file_content)
        
        logger.info(f"ç®¡ç†å‘˜ {current_user.username} ä¸Šä¼ æ–‡ä»¶: {filename}")
        
        return UploadResponse(
            success=True,
            message=f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {filename}",
            filepath=filepath
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.post("/import")
async def trigger_import(
    import_params: ImportRequest = None,
    current_user: User = Depends(require_admin)
):
    """
    è§¦å‘æ•°æ®å¯¼å…¥ï¼ˆåŒæ—¶æ”¯æŒè‚¡ç¥¨æ•°æ®å’Œæ¿å—æ•°æ®ï¼‰
    """
    global import_status
    
    if import_status["is_importing"]:
        raise HTTPException(status_code=400, detail="æ­£åœ¨å¯¼å…¥ä¸­ï¼Œè¯·ç¨åå†è¯•")
    
    try:
        import_status["is_importing"] = True
        import_status["progress"] = 0
        import_status["current_file"] = "æ­£åœ¨å‡†å¤‡å¯¼å…¥..."
        import_status["logs"] = []  # æ¸…ç©ºä¹‹å‰çš„æ—¥å¿—
        
        add_log("ğŸš€ å¼€å§‹æ•°æ®å¯¼å…¥ä»»åŠ¡")
        
        from pathlib import Path
        
        try:
            data_dir = Path(DATA_DIR)
            add_log(f"ğŸ“‚ æ‰«ææ•°æ®ç›®å½•: {data_dir}")
            
            # åˆ†ç±»æ–‡ä»¶
            stock_files = list(data_dir.glob("*_data_sma_feature_color.xlsx"))
            sector_files = list(data_dir.glob("*_allbk_sma_feature_color.xlsx"))
            
            all_files = stock_files + sector_files
            
            add_log(f"ğŸ“Š æ‰¾åˆ° {len(stock_files)} ä¸ªè‚¡ç¥¨æ•°æ®æ–‡ä»¶")
            add_log(f"ğŸ“Š æ‰¾åˆ° {len(sector_files)} ä¸ªæ¿å—æ•°æ®æ–‡ä»¶")
            
            if not all_files:
                import_status["is_importing"] = False
                add_log("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¾…å¯¼å…¥çš„æ–‡ä»¶", "warning")
                return {
                    "success": False,
                    "message": "æ²¡æœ‰æ‰¾åˆ°å¾…å¯¼å…¥çš„ Excel æ–‡ä»¶ï¼ˆæ”¯æŒè‚¡ç¥¨æ•°æ®å’Œæ¿å—æ•°æ®ï¼‰"
                }
            
            total_files = len(all_files)
            imported_count = 0
            errors = []
            
            # å¯¼å…¥è‚¡ç¥¨æ•°æ®
            if stock_files:
                import_status["current_file"] = "å¯¼å…¥è‚¡ç¥¨æ•°æ®..."
                add_log(f"ğŸ“ˆ å¼€å§‹å¯¼å…¥è‚¡ç¥¨æ•°æ® ({len(stock_files)} ä¸ªæ–‡ä»¶)")
                
                from scripts.import_data_robust import import_excel_file as import_stock_file
                from scripts.import_state_manager import get_state_manager
                
                state_manager = get_state_manager()
                
                for i, filepath in enumerate(stock_files):
                    filename = os.path.basename(str(filepath))
                    import_status["current_file"] = f"[è‚¡ç¥¨] {filename}"
                    import_status["progress"] = int((i / total_files) * 50)
                    
                    try:
                        result = import_stock_file(filepath, state_manager)
                        if result[2]:  # success flag
                            imported_count += 1
                            add_log(f"âœ… [è‚¡ç¥¨] {filename} - å¯¼å…¥æˆåŠŸ ({result[0]} æ¡)")
                        else:
                            if result[1] > 0:  # skipped
                                add_log(f"â­ï¸ [è‚¡ç¥¨] {filename} - å·²å­˜åœ¨ï¼Œè·³è¿‡")
                                imported_count += 1
                            else:
                                add_log(f"âŒ [è‚¡ç¥¨] {filename} - å¯¼å…¥å¤±è´¥", "error")
                                errors.append(f"{filename}: å¯¼å…¥è¿”å›å¤±è´¥")
                    except Exception as e:
                        errors.append(f"[è‚¡ç¥¨] {filename}: {str(e)}")
                        add_log(f"âŒ [è‚¡ç¥¨] {filename} - é”™è¯¯: {str(e)}", "error")
            
            # å¯¼å…¥æ¿å—æ•°æ®
            if sector_files:
                import_status["current_file"] = "å¯¼å…¥æ¿å—æ•°æ®..."
                add_log(f"ğŸ“Š å¼€å§‹å¯¼å…¥æ¿å—æ•°æ® ({len(sector_files)} ä¸ªæ–‡ä»¶)")
                
                from scripts.import_sectors_robust import import_sector_excel_file as import_sector_file
                from scripts.import_state_manager import ImportStateManager
                
                sector_state_manager = ImportStateManager("sector_import_state.json")
                
                for i, filepath in enumerate(sector_files):
                    filename = os.path.basename(str(filepath))
                    import_status["current_file"] = f"[æ¿å—] {filename}"
                    import_status["progress"] = int(50 + (i / total_files) * 50)
                    
                    try:
                        result = import_sector_file(filepath, sector_state_manager)
                        if result[2]:  # success flag
                            imported_count += 1
                            add_log(f"âœ… [æ¿å—] {filename} - å¯¼å…¥æˆåŠŸ ({result[0]} æ¡)")
                        else:
                            if result[1] > 0:  # skipped
                                add_log(f"â­ï¸ [æ¿å—] {filename} - å·²å­˜åœ¨ï¼Œè·³è¿‡")
                                imported_count += 1
                            else:
                                add_log(f"âŒ [æ¿å—] {filename} - å¯¼å…¥å¤±è´¥", "error")
                                errors.append(f"{filename}: å¯¼å…¥è¿”å›å¤±è´¥")
                    except Exception as e:
                        errors.append(f"[æ¿å—] {filename}: {str(e)}")
                        add_log(f"âŒ [æ¿å—] {filename} - é”™è¯¯: {str(e)}", "error")
            
            # è®°å½•ç»“æœ
            result = {
                "success": imported_count > 0,
                "message": f"å¯¼å…¥å®Œæˆ: {imported_count}/{total_files} ä¸ªæ–‡ä»¶æˆåŠŸ",
                "imported": imported_count,
                "total": total_files,
                "errors": errors if errors else None
            }
            
            import_status["last_import"] = datetime.now().isoformat()
            import_status["last_result"] = result
            import_status["history"].insert(0, {
                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "result": result
            })
            
            # åªä¿ç•™æœ€è¿‘ 10 æ¡è®°å½•
            import_status["history"] = import_status["history"][:10]
            
            add_log(f"âœ… {result['message']}")
            add_log(f"ğŸ‘¤ æ“ä½œç”¨æˆ·: {current_user.username}")
            
            # é‡è½½å†…å­˜ç¼“å­˜ï¼ˆç¡®ä¿æœ€æ–°æ•°æ®ç«‹å³å¯ç”¨ï¼‰
            add_log("ğŸ”„ æ­£åœ¨é‡è½½å†…å­˜ç¼“å­˜...")
            import_status["current_file"] = "é‡è½½ç¼“å­˜..."
            try:
                from ..core.startup import preload_cache
                preload_cache()
                add_log("âœ… å†…å­˜ç¼“å­˜é‡è½½å®Œæˆï¼æ–°æ•°æ®å·²ç”Ÿæ•ˆ")
            except Exception as cache_error:
                add_log(f"âš ï¸ ç¼“å­˜é‡è½½å¤±è´¥: {str(cache_error)}", "warning")
            
            return result
            
        finally:
            import_status["is_importing"] = False
            import_status["progress"] = 100
            import_status["current_file"] = None
            
    except Exception as e:
        import_status["is_importing"] = False
        add_log(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}", "error")
        raise HTTPException(status_code=500, detail=f"å¯¼å…¥å¤±è´¥: {str(e)}")


@router.get("/import-status")
async def get_import_status(current_user: User = Depends(require_admin)):
    """
    è·å–å¯¼å…¥çŠ¶æ€
    """
    return {
        "is_importing": import_status["is_importing"],
        "current_file": import_status["current_file"],
        "progress": import_status["progress"],
        "last_import": import_status["last_import"],
        "last_result": import_status["last_result"],
        "history": import_status["history"],
        "logs": import_status["logs"]  # å®æ—¶æ—¥å¿—
    }


@router.get("/data-files")
async def list_data_files(current_user: User = Depends(require_admin)):
    """
    åˆ—å‡º data ç›®å½•ä¸­çš„æ–‡ä»¶
    """
    try:
        if not os.path.exists(DATA_DIR):
            return {"files": []}
        
        files = []
        for filename in os.listdir(DATA_DIR):
            filepath = os.path.join(DATA_DIR, filename)
            if os.path.isfile(filepath) and filename.lower().endswith(('.xlsx', '.xls')):
                stat = os.stat(filepath)
                files.append({
                    "name": filename,
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
                })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åº
        files.sort(key=lambda x: x["modified"], reverse=True)
        
        return {"files": files}
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}")


@router.delete("/data-files/{filename}")
async def delete_data_file(
    filename: str,
    current_user: User = Depends(require_admin)
):
    """
    åˆ é™¤ data ç›®å½•ä¸­çš„æ–‡ä»¶
    """
    try:
        # é˜²æ­¢è·¯å¾„éå†æ”»å‡»
        if ".." in filename or "/" in filename or "\\" in filename:
            raise HTTPException(status_code=400, detail="æ— æ•ˆçš„æ–‡ä»¶å")
        
        filepath = os.path.join(DATA_DIR, filename)
        
        if not os.path.exists(filepath):
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        os.remove(filepath)
        logger.info(f"ç®¡ç†å‘˜ {current_user.username} åˆ é™¤æ–‡ä»¶: {filename}")
        
        return {"success": True, "message": f"æ–‡ä»¶å·²åˆ é™¤: {filename}"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")


@router.get("/dates")
async def get_imported_dates(current_user: User = Depends(require_admin)):
    """
    è·å–å·²å¯¼å…¥æ•°æ®çš„æ—¥æœŸåˆ—è¡¨
    """
    try:
        from ..database import SessionLocal
        from sqlalchemy import text
        
        db = SessionLocal()
        try:
            # æŸ¥è¯¢å·²å¯¼å…¥çš„æ—¥æœŸ
            result = db.execute(text("""
                SELECT DISTINCT date 
                FROM daily_stock_data 
                ORDER BY date DESC 
                LIMIT 30
            """))
            dates = [row[0].strftime("%Y-%m-%d") if hasattr(row[0], 'strftime') else str(row[0]) for row in result]
            
            return {"dates": dates}
        finally:
            db.close()
            
    except Exception as e:
        logger.error(f"è·å–æ—¥æœŸåˆ—è¡¨å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–æ—¥æœŸåˆ—è¡¨å¤±è´¥: {str(e)}")
