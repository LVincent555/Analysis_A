"""
è¡Œä¸šåˆ†æç›¸å…³APIè·¯ç”±
"""
from fastapi import APIRouter, HTTPException
from typing import List
from ..services.industry_service_db import industry_service_db
from ..models import IndustryStat, IndustryStats, IndustryStatsWeighted

router = APIRouter(prefix="/api", tags=["industry"])

# ä½¿ç”¨æ•°æ®åº“æœåŠ¡
industry_service = industry_service_db


@router.get("/industry/stats", response_model=List[IndustryStat])
def get_industry_stats(period: int = 3, top_n: int = 20):  # âœ… åŒæ­¥
    """
    è·å–è¡Œä¸šç»Ÿè®¡æ•°æ®
    
    Args:
        period: åˆ†æå‘¨æœŸï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤3
        top_n: æ¯å¤©TOP Nè‚¡ç¥¨ï¼Œé»˜è®¤20
    
    Returns:
        è¡Œä¸šç»Ÿè®¡åˆ—è¡¨
    """
    try:
        return industry_service.analyze_industry(period=period, top_n=top_n)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/industry/trend")
def get_industry_trend(period: int = 14, top_n: int = 100, date: str = None):  # âœ… åŒæ­¥
    """
    è·å–è¡Œä¸šè¶‹åŠ¿æ•°æ®ï¼ˆå¤šæ—¥æœŸåŠ¨æ€å˜åŒ–ï¼‰- ä½¿ç”¨å†…å­˜ç¼“å­˜ä¼˜åŒ– + TTLç¼“å­˜
    
    Args:
        period: åˆ†æå‘¨æœŸï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤14
        top_n: æ¯å¤©TOP Nè‚¡ç¥¨ï¼Œé»˜è®¤100
        date: æŒ‡å®šæ—¥æœŸ (YYYYMMDDæ ¼å¼)ï¼Œä¸ä¼ åˆ™ä½¿ç”¨æœ€æ–°æ—¥æœŸ
    
    Returns:
        è¡Œä¸šè¶‹åŠ¿æ•°æ®ï¼ŒåŒ…å«æ¯æ—¥çš„è¡Œä¸šåˆ†å¸ƒ
    """
    try:
        from datetime import datetime
        from collections import Counter
        from ..services.numpy_cache_middleware import numpy_cache  # âœ… æ–°æ¶æ„
        from ..services.api_cache import api_cache  # âœ… Phase 6 äºŒçº§ç¼“å­˜
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨è·¨è¿›ç¨‹APIç¼“å­˜
        cache_key = f"industry_trend:{period}:{top_n}:{date or 'latest'}"
        cached_result = api_cache.get(cache_key)
        if cached_result is not None:
            return cached_result
        
        # 1. ä»Numpyç¼“å­˜è·å–æ—¥æœŸèŒƒå›´
        if date:
            target_date = datetime.strptime(date, '%Y%m%d').date()
        else:
            target_date = numpy_cache.get_latest_date()
        
        if not target_date:
            return {"data": [], "industries": []}
        
        # è·å–æœ€è¿‘Nå¤©æ—¥æœŸ
        all_dates = numpy_cache.get_dates_range(period * 2)
        target_dates = [d for d in all_dates if d <= target_date][:period]
        
        if not target_dates:
            return {"data": [], "industries": []}
        
        # 2. æ”¶é›†æ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„è‚¡ç¥¨ä»£ç  (è¿”å›Dictåˆ—è¡¨)
        all_stock_codes = set()
        date_stocks_map = {}
        
        for date_obj in target_dates:
            top_stocks = numpy_cache.get_top_n_by_rank(date_obj, top_n)
            date_stocks_map[date_obj] = top_stocks
            all_stock_codes.update(stock['stock_code'] for stock in top_stocks)
        
        # 3. æ‰¹é‡è·å–è‚¡ç¥¨ä¿¡æ¯
        stocks_info = numpy_cache.get_stocks_batch(list(all_stock_codes))
        
        # 4. æŒ‰æ—¥æœŸç»Ÿè®¡è¡Œä¸šåˆ†å¸ƒ
        date_industry_map = {}
        all_industries = set()
        
        for date_obj, top_stocks in date_stocks_map.items():
            date_str = date_obj.strftime('%Y%m%d')
            date_industry_map[date_str] = Counter()
            
            for stock_data in top_stocks:
                stock_info = stocks_info.get(stock_data['stock_code'])
                if stock_info and stock_info.industry:
                    # å¤„ç†è¡Œä¸šå­—æ®µ
                    industry = stock_info.industry
                    if isinstance(industry, list) and industry:
                        industry = industry[0]
                    elif isinstance(industry, str) and industry.startswith('['):
                        import ast
                        try:
                            industry_list = ast.literal_eval(industry)
                            industry = industry_list[0] if industry_list else 'æœªçŸ¥'
                        except:
                            industry = industry.strip('[]').strip("'\"")
                    else:
                        industry = industry if industry else 'æœªçŸ¥'
                    
                    all_industries.add(industry)
                    date_industry_map[date_str][industry] += 1
        
        # 5. æ„å»ºè¿”å›æ•°æ®ï¼ˆä»æ—§åˆ°æ–°æ’åºï¼‰
        data = []
        for date_str in sorted(date_industry_map.keys()):
            data.append({
                "date": date_str,
                "industry_counts": dict(date_industry_map[date_str])
            })
        
        result = {
            "data": data,
            "industries": sorted(list(all_industries))
        }
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šç¼“å­˜ç»“æœï¼ŒTTL=300ç§’ï¼ˆ5åˆ†é’Ÿï¼‰
        api_cache.set(cache_key, result, ttl=300)
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/industry/top1000", response_model=IndustryStats)
def get_top1000_industry(limit: int = 1000, date: str = None):  # âœ… åŒæ­¥
    """
    è·å–å‰Nåè¡Œä¸šç»Ÿè®¡
    
    Args:
        limit: å‰Nåæ•°é‡ï¼Œé»˜è®¤1000ï¼Œå¯é€‰1000/2000/3000/5000
        date: æŒ‡å®šæ—¥æœŸ (YYYYMMDDæ ¼å¼)ï¼Œä¸ä¼ åˆ™ä½¿ç”¨æœ€æ–°æ—¥æœŸ
    
    Returns:
        è¡Œä¸šç»Ÿè®¡æ•°æ®ï¼ˆåŒ…å«æ—¥æœŸå’Œstatsåˆ—è¡¨ï¼‰
    """
    try:
        from datetime import datetime
        from ..services.numpy_cache_middleware import numpy_cache  # âœ… æ–°æ¶æ„
        
        # å‚æ•°éªŒè¯
        if limit not in [1000, 2000, 3000, 5000]:
            limit = 1000  # é»˜è®¤å€¼
        
        # ä»Numpyç¼“å­˜è·å–æ—¥æœŸ
        if date:
            target_date = datetime.strptime(date, '%Y%m%d').date()
        else:
            target_date = numpy_cache.get_latest_date()
        
        if not target_date:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰å¯ç”¨æ•°æ®")
        
        date_str = target_date.strftime('%Y%m%d')
        
        # è·å–ç»Ÿè®¡æ•°æ®ï¼ˆä½¿ç”¨limitå‚æ•°ï¼Œä¼ é€’æ—¥æœŸï¼‰
        stats = industry_service.analyze_industry(
            period=1, 
            top_n=limit,
            target_date=target_date
        )
        total_stocks = sum(s.count for s in stats)
        
        return IndustryStats(
            date=date_str,
            total_stocks=total_stocks,
            stats=stats
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/industry/weighted", response_model=IndustryStatsWeighted)
def get_industry_weighted(  # âœ… åŒæ­¥
    date: str = None,
    k: float = 0.618,
    metric: str = 'B1'
):
    """
    è·å–è¡Œä¸šçƒ­åº¦ç»Ÿè®¡ï¼ˆåŠ æƒç‰ˆæœ¬ï¼‰
    
    å§‹ç»ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼Œé€šè¿‡kå€¼å’ŒæŒ‡æ ‡è°ƒèŠ‚è§†è§’
    
    Args:
        date: æŒ‡å®šæ—¥æœŸ (YYYYMMDDæ ¼å¼)ï¼Œä¸ä¼ åˆ™ä½¿ç”¨æœ€æ–°æ—¥æœŸ
        k: å¹‚å¾‹ç³»æ•°ï¼Œé»˜è®¤0.618ï¼Œå»ºè®®èŒƒå›´[0.382, 1.618]
        metric: æ’åºæŒ‡æ ‡ï¼Œå¯é€‰ï¼š'B1'(æ€»çƒ­åº¦), 'B2'(å¹³å‡çƒ­åº¦), 'C1'(æ€»åˆ†), 'C2'(å¹³å‡åˆ†)
    
    Returns:
        è¡Œä¸šåŠ æƒç»Ÿè®¡æ•°æ®ï¼ŒåŒ…å«4ä¸ªç»´åº¦çš„å®Œæ•´è®¡ç®—ç»“æœ
    """
    try:
        from ..database import SessionLocal
        from ..db_models import DailyStockData, Stock
        from sqlalchemy import desc
        from datetime import datetime
        from collections import defaultdict
        from ..models.industry import IndustryStatWeighted
        
        # å‚æ•°éªŒè¯
        if k < 0.3 or k > 2.0:
            raise HTTPException(status_code=400, detail="kå€¼å¿…é¡»åœ¨0.3-2.0ä¹‹é—´")
        
        if metric not in ['B1', 'B2', 'C1', 'C2']:
            raise HTTPException(status_code=400, detail="metricå¿…é¡»æ˜¯B1/B2/C1/C2ä¹‹ä¸€")
        
        # 1. ä»Numpyç¼“å­˜è·å–æ—¥æœŸ
        from ..services.numpy_cache_middleware import numpy_cache  # âœ… æ–°æ¶æ„
        
        if date:
            target_date = datetime.strptime(date, '%Y%m%d').date()
        else:
            target_date = numpy_cache.get_latest_date()
        
        if not target_date:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰å¯ç”¨æ•°æ®")
        
        date_str = target_date.strftime('%Y%m%d')
        
        # 2. ä»Numpyç¼“å­˜è·å–è¯¥æ—¥æœŸçš„æ‰€æœ‰è‚¡ç¥¨æ•°æ® (è¿”å›Dictåˆ—è¡¨)
        all_stocks = numpy_cache.get_all_by_date(target_date)
        
        if not all_stocks:
            raise HTTPException(status_code=404, detail="è¯¥æ—¥æœŸæ²¡æœ‰æ•°æ®")
        
        # 3. æ‰¹é‡è·å–è‚¡ç¥¨ä¿¡æ¯
        stock_codes = [s['stock_code'] for s in all_stocks]
        stocks_info = numpy_cache.get_stocks_batch(stock_codes)
        
        # 4. æ„å»ºç»“æœï¼ˆrank, score, industryï¼‰
        results = []
        for stock_data in all_stocks:
            stock_info = stocks_info.get(stock_data['stock_code'])
            if stock_info and stock_info.industry:
                results.append((
                    stock_data['rank'],
                    stock_data['total_score'],
                    stock_info.industry
                ))
        
        if not results:
            raise HTTPException(status_code=404, detail="è¯¥æ—¥æœŸæ²¡æœ‰æ•°æ®")
        
        # 5. ä¸€æ¬¡éå†ï¼Œè®¡ç®—æ‰€æœ‰4ä¸ªæŒ‡æ ‡
        industry_data = defaultdict(lambda: {
            'count': 0,
            'total_heat_rank': 0.0,
            'total_score': 0.0
        })
        
        total_stocks = len(results)
        
        for rank, score, industry in results:
            # å¤„ç†è¡Œä¸šå­—æ®µï¼ˆå¯èƒ½æ˜¯æ•°ç»„æˆ–å­—ç¬¦ä¸²ï¼‰
            if isinstance(industry, list) and industry:
                industry = industry[0]
            elif isinstance(industry, str) and industry.startswith('['):
                import ast
                try:
                    industry_list = ast.literal_eval(industry)
                    industry = industry_list[0] if industry_list else 'æœªçŸ¥'
                except:
                    industry = industry.strip('[]').strip("'\"")
            elif not industry:
                industry = 'æœªçŸ¥'
            
            # Bæ–¹æ¡ˆï¼šåŸºäºæ’åçš„åŠ æƒ
            weight_b = 1.0 / (rank ** k)
            
            # Cæ–¹æ¡ˆï¼šåŸºäºæ€»åˆ†çš„åŠ æƒ
            weight_c = float(score) if score else 0.0
            
            # ç´¯åŠ 
            industry_data[industry]['count'] += 1
            industry_data[industry]['total_heat_rank'] += weight_b
            industry_data[industry]['total_score'] += weight_c
        
        # 6. è®¡ç®—å¹³å‡å€¼å¹¶æ„å»ºç»“æœ
        stats = []
        for industry, data in industry_data.items():
            count = data['count']
            percentage = round(count / total_stocks * 100, 2)
            
            stats.append(IndustryStatWeighted(
                industry=industry,
                count=count,
                percentage=percentage,
                total_heat_rank=data['total_heat_rank'],
                avg_heat_rank=data['total_heat_rank'] / count,
                total_score=data['total_score'],
                avg_score=data['total_score'] / count
            ))
        
        # 7. æ ¹æ®æŒ‡å®šçš„metricæ’åº
        if metric == 'B1':
            stats.sort(key=lambda x: x.total_heat_rank, reverse=True)
        elif metric == 'B2':
            stats.sort(key=lambda x: x.avg_heat_rank, reverse=True)
        elif metric == 'C1':
            stats.sort(key=lambda x: x.total_score, reverse=True)
        elif metric == 'C2':
            stats.sort(key=lambda x: x.avg_score, reverse=True)
        
        return IndustryStatsWeighted(
            date=date_str,
            total_stocks=total_stocks,
            k_value=k,
            metric_type=metric,
            stats=stats
        )
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
