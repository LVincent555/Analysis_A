"""
æ•°æ®ç®¡ç†æ ¸å¿ƒæ¨¡å—
è´Ÿè´£æ•°æ®å¯¼å…¥ã€ä¸€è‡´æ€§æ£€éªŒã€è‡ªåŠ¨æ›´æ–°

åœ¨åº”ç”¨å¯åŠ¨å‰è‡ªåŠ¨æ‰§è¡Œï¼š
1. æ•°æ®å¯¼å…¥ï¼ˆå¹‚ç­‰æ€§ï¼‰
2. æ•°æ®ä¸€è‡´æ€§æ£€éªŒ
3. æ•°æ®åº“å¥åº·æ£€æŸ¥
"""
import sys
from pathlib import Path
import logging
from typing import Tuple, Dict

# æ·»åŠ scriptsç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent / "scripts"))

from scripts.import_state_manager import get_state_manager, ImportStateManager
from scripts.import_data_robust import get_data_files, import_excel_file
from scripts.import_sectors_robust import get_sector_data_files, import_sector_excel_file
from ..database import SessionLocal, test_connection
from ..db_models import Stock, DailyStockData
from ..config import DATA_DIR
from sqlalchemy import func, text

logger = logging.getLogger(__name__)


class DataManager:
    """æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.state_manager = get_state_manager()
    
    def auto_import_data(self) -> Tuple[int, int, int, int, int]:
        """
        è‡ªåŠ¨å¯¼å…¥æ–°æ•°æ®ï¼ˆè‚¡ç¥¨+æ¿å—ï¼‰
        
        Returns:
            (æˆåŠŸæ–‡ä»¶æ•°, å¤±è´¥æ–‡ä»¶æ•°, æ€»å¯¼å…¥è®°å½•æ•°, è‚¡ç¥¨å¯¼å…¥æ•°, æ¿å—å¯¼å…¥æ•°)
        """
        logger.info("=" * 60)
        logger.info("ğŸ”„ æ£€æŸ¥å¹¶å¯¼å…¥æ–°æ•°æ®...")
        logger.info("=" * 60)
        
        # 1. å¯¼å…¥è‚¡ç¥¨æ•°æ®
        logger.info("ğŸ“Š æ£€æŸ¥è‚¡ç¥¨æ•°æ®...")
        stock_files = get_data_files()
        if not stock_files:
            logger.info("ğŸ“‚ dataç›®å½•ä¸­æ²¡æœ‰è‚¡ç¥¨æ•°æ®æ–‡ä»¶")
        
        success_count = 0
        failed_count = 0
        stock_imported = 0
        sector_imported = 0
        
        for file_path in stock_files:
            imported, skipped, success = import_excel_file(file_path, self.state_manager)
            stock_imported += imported
            
            if success:
                success_count += 1
            else:
                failed_count += 1
        
        # 2. å¯¼å…¥æ¿å—æ•°æ®ï¼ˆå…è®¸å¤±è´¥ï¼‰
        logger.info("ğŸ“Š æ£€æŸ¥æ¿å—æ•°æ®...")
        sector_state_manager = ImportStateManager(state_file="sector_import_state.json")
        sector_files = get_sector_data_files(DATA_DIR)
        
        if not sector_files:
            logger.info("ğŸ“‚ dataç›®å½•ä¸­æ²¡æœ‰æ¿å—æ•°æ®æ–‡ä»¶")
        
        sector_failed = 0
        for file_path in sector_files:
            try:
                imported, skipped, success = import_sector_excel_file(file_path, sector_state_manager)
                sector_imported += imported
                
                if success:
                    success_count += 1
                else:
                    sector_failed += 1
            except Exception as e:
                logger.warning(f"âš ï¸  æ¿å—æ•°æ®å¯¼å…¥å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {e}")
                sector_failed += 1
        
        # æ¿å—æ•°æ®å¤±è´¥ä¸è®¡å…¥æ€»å¤±è´¥æ•°ï¼ˆå…è®¸åªæœ‰è‚¡ç¥¨æ•°æ®ï¼‰
        if sector_failed > 0:
            logger.warning(f"âš ï¸  æ¿å—æ•°æ®å¯¼å…¥å¤±è´¥ {sector_failed} ä¸ªæ–‡ä»¶ï¼ˆç³»ç»Ÿä»å¯æ­£å¸¸è¿è¡Œï¼‰")
        
        # 3. æ±‡æ€»ç»“æœ
        total_imported = stock_imported + sector_imported
        if total_imported > 0:
            logger.info(f"âœ… æ–°å¯¼å…¥ {total_imported} æ¡è®°å½•ï¼ˆè‚¡ç¥¨: {stock_imported}, æ¿å—: {sector_imported}ï¼‰")
        else:
            logger.info("âœ… æ‰€æœ‰æ•°æ®å·²æ˜¯æœ€æ–°")
        
        return success_count, failed_count, total_imported, stock_imported, sector_imported
    
    def verify_data_consistency(self) -> Dict:
        """
        æ•°æ®ä¸€è‡´æ€§æ£€éªŒ
        
        æ£€æŸ¥é¡¹ï¼š
        1. æ•°æ®åº“è¿æ¥
        2. è‚¡ç¥¨æ€»æ•°
        3. æ¯æ—¥æ•°æ®æ€»æ•°
        4. æ—¥æœŸè¿ç»­æ€§
        5. IDåºåˆ—å®Œæ•´æ€§
        
        Returns:
            æ£€éªŒç»“æœå­—å…¸
        """
        logger.info("=" * 60)
        logger.info("ğŸ” æ•°æ®ä¸€è‡´æ€§æ£€éªŒ...")
        logger.info("=" * 60)
        
        result = {
            "db_connection": False,
            "stock_count": 0,
            "daily_data_count": 0,
            "date_count": 0,
            "id_sequence_ok": False,
            "issues": []
        }
        
        # 1. æ£€æŸ¥æ•°æ®åº“è¿æ¥
        if not test_connection():
            result["issues"].append("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            logger.error("âŒ æ•°æ®åº“è¿æ¥å¤±è´¥")
            return result
        
        result["db_connection"] = True
        logger.info("âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸")
        
        db = SessionLocal()
        try:
            # 2. è‚¡ç¥¨æ€»æ•°
            stock_count = db.query(func.count(Stock.stock_code)).scalar()
            result["stock_count"] = stock_count
            logger.info(f"âœ… è‚¡ç¥¨æ€»æ•°: {stock_count}")
            
            # 3. æ¯æ—¥æ•°æ®æ€»æ•°
            daily_count = db.query(func.count(DailyStockData.id)).scalar()
            result["daily_data_count"] = daily_count
            logger.info(f"âœ… æ¯æ—¥æ•°æ®è®°å½•: {daily_count}")
            
            # 4. æ—¥æœŸæ•°é‡
            date_count = db.query(func.count(func.distinct(DailyStockData.date))).scalar()
            result["date_count"] = date_count
            logger.info(f"âœ… è‚¡ç¥¨æ•°æ®æ—¥æœŸæ•°: {date_count} å¤©")
            
            # 5. IDåºåˆ—æ£€æŸ¥
            if daily_count > 0:
                min_id_result = db.query(func.min(DailyStockData.id)).scalar()
                max_id_result = db.query(func.max(DailyStockData.id)).scalar()
                
                if min_id_result == 1 and max_id_result == daily_count:
                    result["id_sequence_ok"] = True
                    logger.info(f"âœ… è‚¡ç¥¨IDåºåˆ—å®Œæ•´: 1 åˆ° {max_id_result}")
                else:
                    result["issues"].append(f"âš ï¸  è‚¡ç¥¨IDåºåˆ—å¼‚å¸¸: {min_id_result} åˆ° {max_id_result}")
                    logger.warning(f"âš ï¸  è‚¡ç¥¨IDåºåˆ—å¼‚å¸¸")
            
            # 6. æ¿å—æ•°æ®æ£€æŸ¥
            from ..db_models import SectorDailyData
            sector_count = db.query(func.count(SectorDailyData.id)).scalar()
            result["sector_data_count"] = sector_count
            logger.info(f"âœ… æ¿å—æ•°æ®è®°å½•: {sector_count}")
            
            # 7. æ¿å—æ—¥æœŸæ•°é‡
            sector_date_count = db.query(func.count(func.distinct(SectorDailyData.date))).scalar()
            result["sector_date_count"] = sector_date_count
            logger.info(f"âœ… æ¿å—æ•°æ®æ—¥æœŸæ•°: {sector_date_count} å¤©")
            
            # 8. æ¿å—IDåºåˆ—æ£€æŸ¥
            if sector_count > 0:
                min_sector_id = db.query(func.min(SectorDailyData.id)).scalar()
                max_sector_id = db.query(func.max(SectorDailyData.id)).scalar()
                
                if min_sector_id == 1 and max_sector_id == sector_count:
                    result["sector_id_sequence_ok"] = True
                    logger.info(f"âœ… æ¿å—IDåºåˆ—å®Œæ•´: 1 åˆ° {max_sector_id}")
                else:
                    result["issues"].append(f"âš ï¸  æ¿å—IDåºåˆ—å¼‚å¸¸: {min_sector_id} åˆ° {max_sector_id}")
                    logger.warning(f"âš ï¸  æ¿å—IDåºåˆ—å¼‚å¸¸")
            
            # æ±‡æ€»
            if len(result["issues"]) == 0:
                logger.info("=" * 60)
                logger.info("âœ… æ•°æ®ä¸€è‡´æ€§æ£€éªŒé€šè¿‡")
                logger.info("=" * 60)
            else:
                logger.warning("=" * 60)
                logger.warning("âš ï¸  å‘ç° {} ä¸ªé—®é¢˜".format(len(result["issues"])))
                for issue in result["issues"]:
                    logger.warning(f"  {issue}")
                logger.warning("=" * 60)
            
            return result
            
        finally:
            db.close()
    
    def run_startup_checks(self) -> bool:
        """
        å¯åŠ¨å‰æ£€æŸ¥
        æ‰§è¡Œï¼šæ•°æ®å¯¼å…¥ + ä¸€è‡´æ€§æ£€éªŒ
        
        Returns:
            Trueè¡¨ç¤ºé€šè¿‡ï¼ŒFalseè¡¨ç¤ºæœ‰é—®é¢˜
        """
        logger.info("\n")
        logger.info("ğŸš€ " + "=" * 56 + " ğŸš€")
        logger.info("ğŸš€   åº”ç”¨å¯åŠ¨å‰æ•°æ®æ£€æŸ¥")
        logger.info("ğŸš€ " + "=" * 56 + " ğŸš€")
        logger.info("\n")
        
        # 1. è‡ªåŠ¨å¯¼å…¥æ–°æ•°æ®
        success, failed, total_imported, stock_imported, sector_imported = self.auto_import_data()
        
        # åªè¦æœ‰è‚¡ç¥¨æ•°æ®å°±å…è®¸å¯åŠ¨ï¼ˆæ¿å—æ•°æ®æ˜¯å¯é€‰çš„ï¼‰
        if failed > 0:
            logger.warning(f"âš ï¸  æ•°æ®å¯¼å…¥éƒ¨åˆ†å¤±è´¥: {failed} ä¸ªæ–‡ä»¶")
            logger.info(f"ğŸ“Š å·²å¯¼å…¥æ•°æ®: è‚¡ç¥¨ {stock_imported} æ¡, æ¿å— {sector_imported} æ¡")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è‚¡ç¥¨æ•°æ®
            if stock_imported == 0 and total_imported == 0:
                logger.error("âŒ æ²¡æœ‰è‚¡ç¥¨æ•°æ®å¯¼å…¥æˆåŠŸï¼Œæ— æ³•å¯åŠ¨")
                return False
            else:
                logger.info("âœ… è‚¡ç¥¨æ•°æ®å¯¼å…¥æˆåŠŸï¼Œå…è®¸å¯åŠ¨ï¼ˆæ¿å—æ•°æ®å¯é€‰ï¼‰")
        
        # 2. æ•°æ®ä¸€è‡´æ€§æ£€éªŒ
        result = self.verify_data_consistency()
        
        if not result["db_connection"]:
            return False
        
        if result["daily_data_count"] == 0:
            logger.warning("âš ï¸  æ•°æ®åº“ä¸ºç©ºï¼Œè¯·æ£€æŸ¥dataç›®å½•ä¸­æ˜¯å¦æœ‰æ•°æ®æ–‡ä»¶")
            return False
        
        if len(result["issues"]) > 0:
            logger.warning("âš ï¸  æ•°æ®ä¸€è‡´æ€§æ£€éªŒå‘ç°é—®é¢˜ï¼Œä½†å…è®¸å¯åŠ¨")
        
        logger.info("\n")
        logger.info("âœ… " + "=" * 56 + " âœ…")
        logger.info("âœ…   å¯åŠ¨æ£€æŸ¥é€šè¿‡")
        logger.info("âœ… " + "=" * 56 + " âœ…")
        logger.info("\n")
        
        return True


# å…¨å±€å•ä¾‹
_data_manager = None


def get_data_manager() -> DataManager:
    """è·å–æ•°æ®ç®¡ç†å™¨å•ä¾‹"""
    global _data_manager
    if _data_manager is None:
        _data_manager = DataManager()
    return _data_manager


def run_startup_checks() -> bool:
    """ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œå¯åŠ¨æ£€æŸ¥"""
    return get_data_manager().run_startup_checks()
