"""
åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–æ“ä½œ
"""
import logging
from ..services.memory_cache import memory_cache
from ..services.hot_spots_cache import HotSpotsCache
from ..services.industry_detail_service import industry_detail_service
from ..services.stock_service_db import stock_service_db
from ..services.analysis_service_db import analysis_service_db
from ..services.industry_service_db import industry_service_db
from ..services.sector_service_db import sector_service_db

logger = logging.getLogger(__name__)


def preload_cache():
    """åŠ è½½å…¨é‡æ•°æ®åˆ°å†…å­˜ç¼“å­˜"""
    logger.info("ğŸš€ å¯åŠ¨å…¨é‡å†…å­˜ç¼“å­˜...")
    
    try:
        # 1. åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜
        memory_cache.load_all_data()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        stats = memory_cache.get_memory_stats()
        logger.info("=" * 60)
        logger.info("âœ… å…¨é‡å†…å­˜ç¼“å­˜å·²å°±ç»ª")
        logger.info(f"   ğŸ“Š è‚¡ç¥¨æ•°é‡: {stats['stocks_count']:,}")
        logger.info(f"   ğŸ“Š è‚¡ç¥¨æ•°æ®è®°å½•: {stats['daily_data_count']:,}")
        logger.info(f"   ğŸ“Š è‚¡ç¥¨äº¤æ˜“æ—¥æ•°: {stats['dates_count']:,}")
        logger.info(f"   ğŸ“Š æ¿å—æ•°æ®è®°å½•: {stats['sector_daily_data_count']:,}")
        logger.info(f"   ğŸ“Š æ¿å—äº¤æ˜“æ—¥æ•°: {stats['sector_dates_count']:,}")
        logger.info(f"   âš¡ æŸ¥è¯¢æ€§èƒ½: < 1ms")
        logger.info("=" * 60)
        
        # 2. æ¸…ç†æ—§ç¼“å­˜ï¼ˆé‡è¦ï¼šé€»è¾‘å·²æ›´æ”¹ï¼‰
        logger.info("ğŸ§¹ æ¸…ç†æ—§ç¼“å­˜...")
        HotSpotsCache.clear_cache()
        
        # æ¸…ç†æ‰€æœ‰æœåŠ¡çš„TTLCache
        industry_detail_count = industry_detail_service.cache.clear()
        stock_count = stock_service_db.cache.clear()
        analysis_count = analysis_service_db.cache.clear()
        industry_count = industry_service_db.cache.clear()
        sector_count = sector_service_db.cache.clear()
        
        total_cleared = industry_detail_count + stock_count + analysis_count + industry_count + sector_count
        logger.info(f"   âœ… å·²æ¸…ç†è¡Œä¸šè¯¦æƒ…ç¼“å­˜: {industry_detail_count} é¡¹")
        logger.info(f"   âœ… å·²æ¸…ç†ä¸ªè‚¡ç¼“å­˜: {stock_count} é¡¹")
        logger.info(f"   âœ… å·²æ¸…ç†åˆ†æç¼“å­˜: {analysis_count} é¡¹")
        logger.info(f"   âœ… å·²æ¸…ç†è¡Œä¸šç»Ÿè®¡ç¼“å­˜: {industry_count} é¡¹")
        logger.info(f"   âœ… å·²æ¸…ç†æ¿å—ç¼“å­˜: {sector_count} é¡¹")
        logger.info(f"   ğŸ“Š æ€»è®¡æ¸…ç†: {total_cleared} é¡¹")
        
        # 3. é¢„åŠ è½½çƒ­ç‚¹æ¦œç¼“å­˜ï¼ˆæœ€è¿‘3å¤©ï¼‰
        logger.info("ğŸ”¥ é¢„åŠ è½½çƒ­ç‚¹æ¦œç¼“å­˜ï¼ˆæœ€è¿‘3å¤©ï¼‰...")
        HotSpotsCache.preload_recent_dates(days=3)
        
        hot_stats = HotSpotsCache.get_cache_stats()
        logger.info("=" * 60)
        logger.info("âœ… çƒ­ç‚¹æ¦œç¼“å­˜å·²å°±ç»ª")
        logger.info(f"   ğŸ“… å·²ç¼“å­˜æ—¥æœŸ: {', '.join(hot_stats['cached_dates'][:5])}")
        logger.info(f"   ğŸ“Š ç¼“å­˜å¤©æ•°: {hot_stats['total_dates']}")
        logger.info(f"   ğŸ’¾ å†…å­˜å ç”¨: {hot_stats['memory_usage_kb']} KB")
        logger.info(f"   âš¡ æŸ¥è¯¢æ€§èƒ½: O(1)")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ å†…å­˜ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
        raise
