#!/usr/bin/env python3
"""æµ‹è¯•Numpyä¼˜åŒ–æ•ˆæœ"""
import sys
import os
import time

# æ·»åŠ backendç›®å½•åˆ°è·¯å¾„
backend_dir = os.path.join(os.path.dirname(__file__), 'backend')
sys.path.insert(0, backend_dir)

from app.services.memory_cache import memory_cache
from app.services.numpy_cache import numpy_stock_cache

print("=" * 60)
print("Numpyä¼˜åŒ–æ•ˆæœæµ‹è¯•")
print("=" * 60)

# åŠ è½½æ•°æ®
if not memory_cache.is_loaded():
    print("\nåŠ è½½å†…å­˜ç¼“å­˜...")
    start_time = time.time()
    memory_cache.load_all_data()
    load_time = time.time() - start_time
    print(f"âœ… åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}ç§’")

# è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ
print("\n" + "=" * 60)
print("å†…å­˜å ç”¨å¯¹æ¯”")
print("=" * 60)

numpy_usage = numpy_stock_cache.get_memory_usage()
print(f"\nğŸ“Š Numpyç¼“å­˜:")
print(f"  æ•°ç»„å†…å­˜: {numpy_usage['array_mb']:.2f} MB")
print(f"  ç´¢å¼•å†…å­˜: {numpy_usage['dict_mb']:.2f} MB")
print(f"  æ€»è®¡: {numpy_usage['total_mb']:.2f} MB")
print(f"  è®°å½•æ•°: {numpy_usage['n_records']:,}")
print(f"  è‚¡ç¥¨æ•°: {numpy_usage['n_stocks']:,}")
print(f"  äº¤æ˜“æ—¥: {numpy_usage['n_dates']}")

# ä¼°ç®—ä¼ ç»ŸPythonå¯¹è±¡å†…å­˜å ç”¨
# æ¯æ¡DailyStockDataå¯¹è±¡çº¦500-1000å­—èŠ‚
traditional_mb = numpy_usage['n_records'] * 800 / 1024 / 1024
print(f"\nğŸ“¦ ä¼ ç»ŸPythonå¯¹è±¡ï¼ˆä¼°ç®—ï¼‰:")
print(f"  çº¦ {traditional_mb:.2f} MB")

print(f"\nğŸ’¾ èŠ‚çœå†…å­˜: {traditional_mb - numpy_usage['total_mb']:.2f} MB")
print(f"ğŸ“‰ å‡å°‘: {(1 - numpy_usage['total_mb']/traditional_mb)*100:.1f}%")

# æ€§èƒ½æµ‹è¯•
print("\n" + "=" * 60)
print("æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
print("=" * 60)

# è·å–æµ‹è¯•æ•°æ®
latest_date = memory_cache.get_latest_date()
if latest_date:
    top_stocks = memory_cache.get_top_n_stocks(latest_date, 10)
    test_stock_code = top_stocks[0].stock_code if top_stocks else None
    
    if test_stock_code:
        print(f"\næµ‹è¯•è‚¡ç¥¨: {test_stock_code}")
        print(f"æµ‹è¯•æ—¥æœŸ: {latest_date}")
        
        # æµ‹è¯•1: NumpyæŸ¥è¯¢
        n_queries = 1000
        start_time = time.time()
        for _ in range(n_queries):
            data = numpy_stock_cache.get_data(test_stock_code, latest_date)
        numpy_time = (time.time() - start_time) / n_queries * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        print(f"\nâš¡ NumpyæŸ¥è¯¢:")
        print(f"  {n_queries}æ¬¡æŸ¥è¯¢å¹³å‡è€—æ—¶: {numpy_time:.3f} ms")
        print(f"  æ•°æ®ç¤ºä¾‹: rank={data['rank']}, close_price={data['close_price']:.2f}")
        
        # æµ‹è¯•2: ä¼ ç»ŸæŸ¥è¯¢ï¼ˆä»å­—å…¸ï¼‰
        start_time = time.time()
        for _ in range(n_queries):
            data = memory_cache.get_daily_data(test_stock_code, latest_date)
        dict_time = (time.time() - start_time) / n_queries * 1000
        
        print(f"\nğŸ“š ä¼ ç»Ÿå­—å…¸æŸ¥è¯¢:")
        print(f"  {n_queries}æ¬¡æŸ¥è¯¢å¹³å‡è€—æ—¶: {dict_time:.3f} ms")
        
        if numpy_time < dict_time:
            speedup = dict_time / numpy_time
            print(f"\nğŸš€ NumpyæŸ¥è¯¢å¿« {speedup:.1f}x")
        
        # æµ‹è¯•3: æ‰¹é‡æŸ¥è¯¢å†å²
        print("\n" + "=" * 60)
        print("æ‰¹é‡å†å²æŸ¥è¯¢æµ‹è¯•")
        print("=" * 60)
        
        start_time = time.time()
        history = numpy_stock_cache.get_stock_history(test_stock_code, days=7)
        numpy_history_time = (time.time() - start_time) * 1000
        
        print(f"\nâš¡ Numpyæ‰¹é‡æŸ¥è¯¢(7å¤©):")
        print(f"  è€—æ—¶: {numpy_history_time:.3f} ms")
        print(f"  è¿”å›è®°å½•æ•°: {len(history)}")
        
        # æµ‹è¯•4: Top NæŸ¥è¯¢
        print("\n" + "=" * 60)
        print("Top NæŸ¥è¯¢æµ‹è¯•")
        print("=" * 60)
        
        start_time = time.time()
        top_100 = numpy_stock_cache.get_top_n_by_rank(latest_date, 100)
        numpy_topn_time = (time.time() - start_time) * 1000
        
        print(f"\nâš¡ Numpy Top100æŸ¥è¯¢:")
        print(f"  è€—æ—¶: {numpy_topn_time:.3f} ms")
        print(f"  è¿”å›è‚¡ç¥¨æ•°: {len(top_100)}")
        print(f"  å‰5åª: {top_100[:5]}")

print("\n" + "=" * 60)
print("âœ… æµ‹è¯•å®Œæˆ")
print("=" * 60)
